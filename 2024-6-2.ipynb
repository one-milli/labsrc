{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最適化問題\n",
    "\n",
    "$$ \\min_h \\|\\bm{g}-F' \\bm{h}\\|\\_2^2+\\lambda_1\\|\\bm{h}\\|\\_1 + \\lambda_2\\|D\\bm{h}\\|\\_1$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パラメータ設定\n",
    "n = 64\n",
    "m = 128\n",
    "N = n**2\n",
    "M = m**2\n",
    "LAMBDA1 = 1\n",
    "LAMBDA2 = 1\n",
    "SEED = 3\n",
    "RATIO = 0.1\n",
    "DATA_PATH = '../../OneDrive - m.titech.ac.jp/Lab/data'\n",
    "IMG_NAME = 'hadamard'\n",
    "DIRECTORY = DATA_PATH + '/240626'\n",
    "SETTING = f\"{IMG_NAME}_l1_p-{int(100*RATIO)}_lmd1-{int(LAMBDA1)}_lmd2-{int(LAMBDA2)}_seed-{SEED}\"\n",
    "\n",
    "if not os.path.exists(DIRECTORY):\n",
    "    os.makedirs(DIRECTORY)\n",
    "if not os.path.exists(DIRECTORY + '/systemMatrix'):\n",
    "    os.makedirs(DIRECTORY + '/systemMatrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grad\n",
    "Di = sparse.eye(M, format='csr') - sparse.eye(M, k=m, format='csr')\n",
    "Di[-m:, :] = 0\n",
    "\n",
    "Dj = sparse.eye(M, format='csr') - sparse.eye(M, k=1, format='csr')\n",
    "for p in range(1, m + 1):\n",
    "    Dj[m * p - 1, m * p - 1] = 0\n",
    "    if p < m:\n",
    "        Dj[m * p - 1, m * p] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix2vector(matrix):\n",
    "    return matrix.T.flatten()\n",
    "\n",
    "\n",
    "def vector2matrix(vector, s, t):\n",
    "    \"\"\"txs matrix\"\"\"\n",
    "    return vector.reshape(s, t).T\n",
    "\n",
    "\n",
    "def mult_mass(F, h, M):\n",
    "    N = F.shape[1]\n",
    "    H = h.reshape(N, M)\n",
    "    res = F @ H\n",
    "    return res.flatten()\n",
    "\n",
    "\n",
    "def mult_Dij(h):\n",
    "    H = vector2matrix(h, N, M)\n",
    "    res = np.hstack([Di @ H, Dj @ H])\n",
    "    return matrix2vector(res)\n",
    "\n",
    "\n",
    "def mult_DijT(y):\n",
    "    y1 = y[:M * N]\n",
    "    y2 = y[M * N:]\n",
    "    Y1 = vector2matrix(y1, N, M)\n",
    "    Y2 = vector2matrix(y2, N, M)\n",
    "    res = Di.T @ Y1 + Dj.T @ Y2\n",
    "    return matrix2vector(res)\n",
    "\n",
    "\n",
    "def images_to_matrix(folder_path, convert_gray=True, rand=True, ratio=RATIO):\n",
    "    files = os.listdir(folder_path)\n",
    "    files.sort(key=lambda f: int(re.search(f\"{IMG_NAME}_(\\d+).png\", f).group(1)))\n",
    "    if rand:\n",
    "        random.seed(SEED)\n",
    "        random.shuffle(files)\n",
    "\n",
    "    total_files = len(files)\n",
    "    number_of_files_to_load = int(total_files * ratio)\n",
    "    selected_files = files[:number_of_files_to_load]\n",
    "    selected_files.sort(key=lambda f: int(re.search(f\"{IMG_NAME}_(\\d+).png\", f).group(1)))\n",
    "\n",
    "    images = []\n",
    "    use_list = []\n",
    "\n",
    "    for file in selected_files:\n",
    "        index = int(re.sub(r'\\D', '', file))\n",
    "        use_list.append(index)\n",
    "        img = Image.open(os.path.join(folder_path, file))\n",
    "        if convert_gray:\n",
    "            img = img.convert('L')\n",
    "        img_array = np.asarray(img).flatten()\n",
    "        img_array = img_array / 255\n",
    "        images.append(img_array)\n",
    "\n",
    "    return np.column_stack(images), use_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prox_l1(x: np.ndarray, alpha: float) -> np.ndarray:\n",
    "    \"\"\"Proximal operator for L1 norm.\"\"\"\n",
    "    return np.sign(x) * np.maximum(np.abs(x) - alpha, 0)\n",
    "\n",
    "\n",
    "def prox_l1_conj(x: np.ndarray, alpha: float) -> np.ndarray:\n",
    "    \"\"\"Proximal operator for conjugate L1 norm.\"\"\"\n",
    "    return x - alpha * prox_l1(x / alpha, 1 / alpha)\n",
    "\n",
    "\n",
    "def prox_l122(Y, gamma):\n",
    "    N = Y.shape[1]\n",
    "    l1_norms = np.sum(np.abs(Y), axis=1)\n",
    "    factor = (2 * gamma) / (1 + 2 * gamma * N)\n",
    "    X = np.zeros_like(Y)\n",
    "    X = np.sign(Y) * np.maximum(np.abs(Y) - factor * l1_norms[:, np.newaxis], 0)\n",
    "    return X\n",
    "\n",
    "\n",
    "def primal_dual_splitting(\n",
    "    F: sparse.csr_matrix,\n",
    "    g: np.ndarray,\n",
    "    lambda1: float,\n",
    "    lambda2: float,\n",
    "    max_iter: int = 1000,\n",
    "    tol: float = 1e-2,\n",
    ") -> tuple[np.ndarray, dict]:\n",
    "    \"\"\"\n",
    "    Solve the optimization problem:\n",
    "    min_h ||g-Fh||_2^2 + lambda1||h||_1 + lambda2||Dh||_1\n",
    "    using the primal-dual splitting method.\n",
    "\n",
    "    Args:\n",
    "        F (np.ndarray): Matrix F in the problem formulation.\n",
    "        g (np.ndarray): Vector g in the problem formulation.\n",
    "        lambda1 (float): Regularization parameter for L1 norm of h.\n",
    "        lambda2 (float): Regularization parameter for L1 norm of Dh.\n",
    "        h_init (np.ndarray, optional): Initial guess for h. If None, initialized with zeros.\n",
    "        y_init (np.ndarray, optional): Initial guess for y. If None, initialized with zeros.\n",
    "        max_iter (int): Maximum number of iterations.\n",
    "        tol (float): Tolerance for convergence.\n",
    "        adaptive_params (bool): Whether to use adaptive step sizes.\n",
    "\n",
    "    Returns:\n",
    "        tuple[np.ndarray, dict]: Solution h and a dictionary containing additional information.\n",
    "    \"\"\"\n",
    "    h = np.zeros(N * M)\n",
    "    y = np.zeros(2 * N * M)\n",
    "\n",
    "    # Initialize step sizes\n",
    "    tau = 1.0 / (np.linalg.norm(F, 2) ** 2)  # 1 / Compute Lipschitz constant of grad_f\n",
    "    sigma = 1.0 / ((2 * M * N * 2) ** 2)  # 1 / l2 norm of Dij ^ 2\n",
    "\n",
    "    # objective_values = []\n",
    "    for k in range(max_iter):\n",
    "        h_old = h.copy()\n",
    "        y_old = y.copy()\n",
    "\n",
    "        # Update primal variable h\n",
    "        grad = mult_mass(F.T, (mult_mass(F, h_old, m ** 2) - g), m ** 2)\n",
    "        h = prox_l1(h - tau * (grad - mult_DijT(y)), tau * lambda1)\n",
    "\n",
    "        # Update dual variable y\n",
    "        y = prox_l1_conj(y + sigma * mult_Dij(2 * h - h_old), sigma / lambda2)\n",
    "\n",
    "        # Compute objective value\n",
    "        # obj_value = np.linalg.norm(\n",
    "        #     g - mult_mass(F, h, m**2))**2 + lambda1 * np.linalg.norm(h, 1) + lambda2 * np.linalg.norm(mult_Dij(h), 1)\n",
    "        # objective_values.append(obj_value)\n",
    "\n",
    "        # Check convergence\n",
    "        primal_residual = np.linalg.norm(h - h_old)\n",
    "        dual_residual = np.linalg.norm(y - y_old)\n",
    "        print(\n",
    "            f\"iter={k}, primal_res={primal_residual:.4f}, dual_res={dual_residual:.4f}\")\n",
    "        if primal_residual < tol and dual_residual < tol:\n",
    "            break\n",
    "\n",
    "    info = {\n",
    "        \"iterations\": k + 1,\n",
    "        # \"objective_values\": objective_values,\n",
    "        # \"final_objective\": objective_values[-1],\n",
    "        \"primal_residual\": primal_residual,\n",
    "        \"dual_residual\": dual_residual\n",
    "    }\n",
    "\n",
    "    return h, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images\n",
    "G, use = images_to_matrix(f\"{DATA_PATH}/{IMG_NAME}{n}_cap_R_230516_128/\")\n",
    "F, _ = images_to_matrix(f\"{DATA_PATH}/{IMG_NAME}{n}_input/\")\n",
    "print(\"K=\", F.shape[1])\n",
    "white_img = Image.open(f\"{DATA_PATH}/{IMG_NAME}{n}_cap_R_230516_128/{IMG_NAME}_1.png\")\n",
    "white_img = white_img.convert('L')\n",
    "white_img = np.asarray(white_img) / 255\n",
    "white = white_img.flatten()\n",
    "white = white[:, np.newaxis]\n",
    "H1 = np.tile(white, F.shape[1])\n",
    "F_hat = 2 * F - 1\n",
    "G_hat = 2 * G - H1\n",
    "\n",
    "g = matrix2vector(G_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dk = sparse.eye(N, format='csr') - sparse.eye(N, k=n, format='csr')\n",
    "# Dk = sparse.csr_matrix(Dk[:n * (n - 1), :N])\n",
    "# Dk = sparse.vstack([Dk, sparse.csr_matrix((n, N))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dl = sparse.eye(N, format='csr') - sparse.eye(N, k=1, format='csr')\n",
    "# for p in range(1, n + 1):\n",
    "#     Dl[n * p - 1, n * p - 1] = 0\n",
    "#     if p < n:\n",
    "#         Dl[n * p - 1, n * p] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DI = sparse.kron(sparse.eye(N, format='csr'), Di)\n",
    "# DJ = sparse.kron(sparse.eye(N, format='csr'), Dj)\n",
    "# DK = sparse.kron(Dk, sparse.eye(M, format='csr'))\n",
    "# DL = sparse.kron(Dl, sparse.eye(M, format='csr'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, info = primal_dual_splitting(F_hat.T, g, LAMBDA1, LAMBDA2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = vector2matrix(h, n**2, m**2)\n",
    "np.save(f\"{DIRECTORY}/systemMatrix/H_matrix_{SETTING}.npy\", H)\n",
    "\n",
    "sample_image = Image.open(f\"{DATA_PATH}/sample_image64/Cameraman64.png\").convert('L')\n",
    "sample_image = np.asarray(sample_image).flatten() / 255\n",
    "\n",
    "Hf = H @ sample_image\n",
    "Hf_img = Hf.reshape(m, m)\n",
    "Hf_img = np.clip(Hf_img, 0, 1)\n",
    "Hf_pil = Image.fromarray((Hf_img * 255).astype(np.uint8), mode='L')\n",
    "\n",
    "FILENAME = f\"Cameraman64_{SETTING}.png\"\n",
    "fig, ax = plt.subplots(figsize=Hf_img.shape[::-1], dpi=1, tight_layout=True)\n",
    "ax.imshow(Hf_pil, cmap='gray')\n",
    "ax.axis('off')\n",
    "fig.savefig(f\"{DIRECTORY}/{FILENAME}\", dpi=1)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

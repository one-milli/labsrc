{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最適化問題\n",
    "\n",
    "$$ \\min*h \\|\\bm{g}-F^\\top \\bm{h}\\|\\_2^2+\\lambda_1\\|\\bm{h}\\|*{1,2}^2 + \\lambda*2\\|D\\bm{h}\\|*{1,2}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from scipy.sparse.linalg import norm, spsolve\n",
    "from typing import Callable, Union\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パラメータ設定\n",
    "n = 64\n",
    "m = 128\n",
    "LAMBDA1 = 1\n",
    "LAMBDA2 = 1\n",
    "SEED = 2\n",
    "RATIO = 0.1\n",
    "DATA_PATH = \"../../OneDrive - m.titech.ac.jp/Lab/data\"\n",
    "IMG_NAME = \"hadamard\"\n",
    "DIRECTORY = DATA_PATH + \"/240718\"\n",
    "SETTING = f\"{IMG_NAME}_l1_p-{int(100*RATIO)}_lmd1-{int(LAMBDA1)}_lmd2-{int(LAMBDA2)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix2vector(matrix):\n",
    "    return matrix.T.flatten()\n",
    "\n",
    "\n",
    "def vector2matrix(vector, s, t):\n",
    "    return vector.reshape(s, t).T\n",
    "\n",
    "\n",
    "def mult_mass(F, h, M):\n",
    "    N = F.shape[1]\n",
    "    h = h.reshape(N, M)\n",
    "    res = F @ h\n",
    "    return res.flatten()\n",
    "\n",
    "\n",
    "def images_to_matrix(folder_path, convert_gray=True, rand=True, ratio=RATIO):\n",
    "    files = os.listdir(folder_path)\n",
    "    files.sort(key=lambda f: int(re.search(f\"{IMG_NAME}_(\\d+).png\", f).group(1)))\n",
    "    if rand:\n",
    "        random.seed(SEED)\n",
    "        random.shuffle(files)\n",
    "\n",
    "    total_files = len(files)\n",
    "    number_of_files_to_load = int(total_files * ratio)\n",
    "    selected_files = files[:number_of_files_to_load]\n",
    "    selected_files.sort(key=lambda f: int(re.search(f\"{IMG_NAME}_(\\d+).png\", f).group(1)))\n",
    "\n",
    "    images = []\n",
    "    use_list = []\n",
    "\n",
    "    for file in selected_files:\n",
    "        index = int(re.sub(r\"\\D\", \"\", file))\n",
    "        use_list.append(index)\n",
    "        img = Image.open(os.path.join(folder_path, file))\n",
    "        if convert_gray:\n",
    "            img = img.convert(\"L\")\n",
    "        img_array = np.asarray(img).flatten()\n",
    "        img_array = img_array / 255\n",
    "        images.append(img_array)\n",
    "\n",
    "    return np.column_stack(images), use_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prox_l1(x: np.ndarray, alpha: float) -> np.ndarray:\n",
    "    \"\"\"Proximal operator for L1 norm.\"\"\"\n",
    "    return np.sign(x) * np.maximum(np.abs(x) - alpha, 0)\n",
    "\n",
    "\n",
    "def prox_l122(y: np.ndarray, gamma: float) -> np.ndarray:\n",
    "    Y = vector2matrix(y, n**2, m**2)\n",
    "    N = Y.shape[1]\n",
    "    l1_norms = np.sum(np.abs(Y), axis=1)\n",
    "    factor = (2 * gamma) / (1 + 2 * gamma * N)\n",
    "    X = np.zeros_like(Y)\n",
    "    X = np.sign(Y) * np.maximum(np.abs(Y) - factor * l1_norms[:, np.newaxis], 0)\n",
    "    return matrix2vector(X)\n",
    "\n",
    "\n",
    "def prox_conj(prox: Callable[[np.ndarray, float], np.ndarray], x: np.ndarray, alpha: float) -> np.ndarray:\n",
    "    \"\"\"Conjugate proximal operator.\"\"\"\n",
    "    return x - alpha * prox(x / alpha, 1 / alpha)\n",
    "\n",
    "\n",
    "def grad_h(h: np.ndarray, X: np.ndarray, g: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Gradient of ||g - Xh||_2^2.\"\"\"\n",
    "    return 2 * X.T @ (X @ h - g)\n",
    "\n",
    "\n",
    "def primal_dual_splitting(\n",
    "    X: np.ndarray,\n",
    "    D: np.ndarray,\n",
    "    g: np.ndarray,\n",
    "    lambda1: float,\n",
    "    lambda2: float,\n",
    "    max_iter: int = 1000,\n",
    "    tol: float = 1e-2,\n",
    ") -> tuple[np.ndarray, dict]:\n",
    "    \"\"\"\n",
    "    Solve the optimization problem:\n",
    "    min_h ||g-Fh||_2^2 + lambda1 P(h) + lambda2 ||Dh||_{1,2}\n",
    "    using the primal-dual splitting method.\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray): Matrix X in the problem formulation.\n",
    "        D (np.ndarray): Gradient matrix D.\n",
    "        g (np.ndarray): Vector g in the problem formulation.\n",
    "        lambda1 (float): Regularization parameter for L1 norm of h.\n",
    "        lambda2 (float): Regularization parameter for L1 norm of Dh.\n",
    "        h_init (np.ndarray, optional): Initial guess for h. If None, initialized with zeros.\n",
    "        y_init (np.ndarray, optional): Initial guess for y. If None, initialized with zeros.\n",
    "        max_iter (int): Maximum number of iterations.\n",
    "        tol (float): Tolerance for convergence.\n",
    "\n",
    "    Returns:\n",
    "        tuple[np.ndarray, dict]: Solution h and a dictionary containing additional information.\n",
    "    \"\"\"\n",
    "    MK, MN = X.shape\n",
    "    h = np.zeros(MN)\n",
    "    y = np.zeros(D.shape[0])\n",
    "\n",
    "    # Compute Lipschitz constant of grad_f\n",
    "    L = norm(X, 2) ** 2\n",
    "\n",
    "    tau = 1.0 / L\n",
    "    sigma = 1.0 / (norm(D, 2) ** 2)\n",
    "\n",
    "    objective_values = []\n",
    "    for k in range(max_iter):\n",
    "        h_old = h.copy()\n",
    "        y_old = y.copy()\n",
    "\n",
    "        # Update primal variable h\n",
    "        grad = grad_h(h_old, X, g)\n",
    "        h = prox_l1(h - tau * (grad - D.T @ y), tau * lambda1)\n",
    "\n",
    "        # Update dual variable y\n",
    "        y = prox_conj(prox_l1, y + sigma * D @ (2 * h - h_old), sigma / lambda2)\n",
    "\n",
    "        # Compute objective value\n",
    "        obj_value = np.linalg.norm(g - X @ h) ** 2 + lambda1 * np.linalg.norm(h, 1) + lambda2 * np.linalg.norm(D @ h, 1)\n",
    "        objective_values.append(obj_value)\n",
    "\n",
    "        # Check convergence\n",
    "        primal_residual = np.linalg.norm(h - h_old) / max(np.linalg.norm(h), 1e-8)\n",
    "        dual_residual = np.linalg.norm(y - y_old) / max(np.linalg.norm(y), 1e-8)\n",
    "        print(f\"iter={k}, obj={obj_value:.4f}, primal_res={primal_residual:.4f}, dual_res={dual_residual:.4f}\")\n",
    "        if primal_residual < tol and dual_residual < tol:\n",
    "            break\n",
    "\n",
    "    info = {\n",
    "        \"iterations\": k + 1,\n",
    "        \"objective_values\": objective_values,\n",
    "        \"final_objective\": objective_values[-1],\n",
    "        \"primal_residual\": primal_residual,\n",
    "        \"dual_residual\": dual_residual,\n",
    "    }\n",
    "\n",
    "    return h, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images\n",
    "G, use = images_to_matrix(f\"{DATA_PATH}/{IMG_NAME}{n}_cap_R_230516_128/\")\n",
    "F, _ = images_to_matrix(f\"{DATA_PATH}/{IMG_NAME}{n}_input/\")\n",
    "print(\"K=\", F.shape[1])\n",
    "white_img = Image.open(f\"{DATA_PATH}/{IMG_NAME}{n}_cap_R_230516_128/{IMG_NAME}_1.png\")\n",
    "white_img = white_img.convert(\"L\")\n",
    "white_img = np.asarray(white_img) / 255\n",
    "white = white_img.flatten()\n",
    "white = white[:, np.newaxis]\n",
    "H1 = np.tile(white, F.shape[1])\n",
    "F_hat = 2 * F - 1\n",
    "G_hat = 2 * G - H1\n",
    "\n",
    "g = matrix2vector(G_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.  0. -1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0. -1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "[[ 1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1. -1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  1. -1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1. -1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1. -1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "m = 4\n",
    "M = m**2\n",
    "\n",
    "Di = sparse.lil_matrix((M, M))\n",
    "Dj = sparse.lil_matrix((M, M))\n",
    "Dk = sparse.lil_matrix((M, 2 * M))\n",
    "Dl = sparse.lil_matrix((M, 3 * M))\n",
    "\n",
    "for i in range(m):\n",
    "    for j in range(m):\n",
    "        index = i * m + j\n",
    "        if i < n - 1:\n",
    "            # 内部ピクセルの場合\n",
    "            Di[index, index] = 1\n",
    "            Di[index, index + m] = -1\n",
    "\n",
    "for i in range(m):\n",
    "    for j in range(m):\n",
    "        index = i * m + j\n",
    "        if j < m - 1:\n",
    "            # 内部ピクセルの場合\n",
    "            Dj[index, index] = 1\n",
    "            Dj[index, index + 1] = -1\n",
    "\n",
    "\n",
    "print(Di.toarray())\n",
    "print(Dj.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = sparse.eye(n, n, format=\"csc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, info = primal_dual_splitting(F_hat, D, g, LAMBDA1, LAMBDA2, max_iter=500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

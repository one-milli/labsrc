{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最適化問題\n",
    "\n",
    "$$ \\min_h \\|\\bm{g}-F^\\top \\bm{h}\\|_2^2+\\lambda_1\\|\\bm{h}\\|_{1,2}^2 + \\lambda_2\\|D\\bm{h}\\|_{1,2}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "from typing import Callable\n",
    "import cupy as cp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from scipy import sparse\n",
    "import cupyx.scipy.sparse as csp\n",
    "import cupyx.scipy.ndimage as ndi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 128\n",
    "m = 192\n",
    "N = n**2\n",
    "M = m**2\n",
    "LAMBDA1 = 1e1\n",
    "LAMBDA2 = 1e3\n",
    "SEED = 5\n",
    "RATIO = 0.05\n",
    "ITER = 300\n",
    "DATA_PATH = \"../data\"\n",
    "IMG_NAME = \"hadamard\"\n",
    "DIRECTORY = DATA_PATH + \"/240825\"\n",
    "SETTING = f\"{IMG_NAME}_pr-du_p-{int(100*RATIO)}_lmd1-{LAMBDA1}_lmd2-{LAMBDA2}\"\n",
    "\n",
    "if not os.path.exists(DIRECTORY):\n",
    "    os.makedirs(DIRECTORY)\n",
    "if not os.path.exists(DIRECTORY + \"/systemMatrix\"):\n",
    "    os.makedirs(DIRECTORY + \"/systemMatrix\")\n",
    "\n",
    "# cp.cuda.Device(2).use()\n",
    "# cp.cuda.Device(3).use()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Di_gpu = csp.eye(M, dtype=cp.float32, format='csr') - csp.eye(M, k=m, dtype=cp.float32, format='csr')\n",
    "# Di_gpu[-m:, :] = 0\n",
    "\n",
    "# Dj_gpu = csp.eye(M, dtype=cp.float32, format='csr') - csp.eye(M, k=1, dtype=cp.float32, format='csr')\n",
    "# for p in range(1, m + 1):\n",
    "#     Dj_gpu[m * p - 1, m * p - 1] = 0\n",
    "#     if p < m:\n",
    "#         Dj_gpu[m * p - 1, m * p] = 0\n",
    "\n",
    "# Dk_gpu = csp.eye(N, dtype=cp.float32, format='csr') - csp.eye(N, k=n, dtype=cp.float32, format='csr')\n",
    "# Dk_gpu = csp.csr_matrix(Dk_gpu[:n * (n - 1), :N])\n",
    "# Dk_gpu = csp.vstack([Dk_gpu, csp.csr_matrix((n, N))])\n",
    "\n",
    "# Dl_gpu = csp.eye(N, dtype=cp.float32, format='csr') - csp.eye(N, k=1, dtype=cp.float32, format='csr')\n",
    "# for p in range(1, n + 1):\n",
    "#     Dl_gpu[n * p - 1, n * p - 1] = 0\n",
    "#     if p < n:\n",
    "#         Dl_gpu[n * p - 1, n * p] = 0\n",
    "\n",
    "\n",
    "def compute_differences(H):\n",
    "    # H is expected to be of shape (M, N)\n",
    "    # Reshape H into 4D tensor with shape (m, m, n, n)\n",
    "    H = H.reshape(m, m, n, n, order=\"F\")\n",
    "    # Compute differences along each axis\n",
    "    di = ndi.convolve1d(H, weights=cp.array([-1, 1]), axis=0, mode='constant', cval=0.0)\n",
    "    dj = ndi.convolve1d(H, weights=cp.array([-1, 1]), axis=1, mode='constant', cval=0.0)\n",
    "    dk = ndi.convolve1d(H, weights=cp.array([-1, 1]), axis=2, mode='constant', cval=0.0)\n",
    "    dl = ndi.convolve1d(H, weights=cp.array([-1, 1]), axis=3, mode='constant', cval=0.0)\n",
    "    # Flatten the results\n",
    "    di_flat = di.ravel(order='F')\n",
    "    dj_flat = dj.ravel(order='F')\n",
    "    dk_flat = dk.ravel(order='F')\n",
    "    dl_flat = dl.ravel(order='F')\n",
    "    # Concatenate the results\n",
    "    return cp.concatenate([di_flat, dj_flat, dk_flat, dl_flat])\n",
    "\n",
    "\n",
    "def compute_adjoint_differences(Du):\n",
    "    # Du contains concatenated differences: di, dj, dk, dl\n",
    "    total_elements = M * N\n",
    "    di = Du[0:total_elements].reshape(m, m, n, n, order='F')\n",
    "    dj = Du[total_elements:2*total_elements].reshape(m, m, n, n, order='F')\n",
    "    dk = Du[2*total_elements:3*total_elements].reshape(m, m, n, n, order='F')\n",
    "    dl = Du[3*total_elements:].reshape(m, m, n, n, order='F')\n",
    "    \n",
    "    # Initialize the result\n",
    "    H_adj = cp.zeros((m, m, n, n), dtype=Du.dtype)\n",
    "    \n",
    "    # Convolve with adjoint kernels (flip and sign change)\n",
    "    # For di (axis=0), the adjoint convolution kernel is [1, -1] (flipped and sign-changed)\n",
    "    H_adj += ndi.convolve1d(di, weights=cp.array([1, -1]), axis=0, mode='constant', cval=0.0)\n",
    "    # For dj (axis=1)\n",
    "    H_adj += ndi.convolve1d(dj, weights=cp.array([1, -1]), axis=1, mode='constant', cval=0.0)\n",
    "    # For dk (axis=2)\n",
    "    H_adj += ndi.convolve1d(dk, weights=cp.array([1, -1]), axis=2, mode='constant', cval=0.0)\n",
    "    # For dl (axis=3)\n",
    "    H_adj += ndi.convolve1d(dl, weights=cp.array([1, -1]), axis=3, mode='constant', cval=0.0)\n",
    "    \n",
    "    # Flatten the result\n",
    "    H_adj_flat = H_adj.ravel(order='F')\n",
    "    return H_adj_flat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix2vectorNp(matrix: np.ndarray) -> np.ndarray:\n",
    "    return matrix.reshape(-1, 1, order=\"F\").flatten()\n",
    "\n",
    "\n",
    "def matrix2vectorCp(matrix: cp.ndarray) -> cp.ndarray:\n",
    "    return matrix.reshape(-1, 1, order=\"F\").flatten()\n",
    "\n",
    "\n",
    "def vector2matrixNp(vector: np.ndarray, s: int, t: int) -> np.ndarray:\n",
    "    return vector.reshape(s, t, order=\"F\")\n",
    "\n",
    "\n",
    "def vector2matrixCp(vector: cp.ndarray, s: int, t: int) -> cp.ndarray:\n",
    "    return vector.reshape(s, t, order=\"F\")\n",
    "\n",
    "\n",
    "def mult_mass(X: cp.ndarray, h: cp.ndarray) -> cp.ndarray:\n",
    "    return (h.reshape(M, -1, order=\"F\") @ X.T).ravel(order=\"F\")\n",
    "\n",
    "\n",
    "def mult_Dijkl(h: cp.ndarray) -> cp.ndarray:\n",
    "    return compute_differences(h.reshape(M, N, order=\"F\"))\n",
    "\n",
    "\n",
    "# def mult_Dijkl(h: cp.ndarray, memptr) -> cp.ndarray:\n",
    "# with cp.cuda.Device(h.device.id):\n",
    "#     H = vector2matrixCp(h, M, N)\n",
    "#     res_gpu = cp.ndarray((4 * M * N), dtype=cp.float16, memptr=memptr)\n",
    "#     res_gpu[: M * N] = matrix2vectorCp(Di_gpu @ H)\n",
    "#     res_gpu[M * N : 2 * M * N] = matrix2vectorCp(Dj_gpu @ H)\n",
    "#     res_gpu[2 * M * N : 3 * M * N] = matrix2vectorCp(H @ Dk_gpu.T)\n",
    "#     res_gpu[3 * M * N :] = matrix2vectorCp(H @ Dl_gpu.T)\n",
    "#     return res_gpu\n",
    "\n",
    "\n",
    "def mult_DijklT(y: cp.ndarray) -> cp.ndarray:\n",
    "    return compute_adjoint_differences(y)\n",
    "\n",
    "\n",
    "# def mult_DijklT(y: cp.ndarray, memptr) -> cp.ndarray:\n",
    "#     with cp.cuda.Device(y.device.id):\n",
    "#         res_gpu = cp.ndarray((M, N), dtype=cp.float16, memptr=memptr)\n",
    "#         res_gpu[:] = Di_gpu.T @ vector2matrixCp(y[: M * N], M, N)\n",
    "#         res_gpu[:] += Dj_gpu.T @ vector2matrixCp(y[M * N : 2 * M * N], M, N)\n",
    "#         res_gpu[:] += vector2matrixCp(y[2 * M * N : 3 * M * N], M, N) @ Dk_gpu.T\n",
    "#         res_gpu[:] += vector2matrixCp(y[3 * M * N :], M, N) @ Dl_gpu.T\n",
    "#         return matrix2vectorCp(res_gpu)\n",
    "\n",
    "\n",
    "def images_to_matrix(folder_path, convert_gray=True, rand=True, ratio=RATIO, resize=False):\n",
    "    files = os.listdir(folder_path)\n",
    "    files.sort(key=lambda f: int(re.search(f\"{IMG_NAME}_(\\d+).png\", f).group(1)))\n",
    "    if rand:\n",
    "        random.seed(SEED)\n",
    "        random.shuffle(files)\n",
    "\n",
    "    total_files = len(files)\n",
    "    number_of_files_to_load = int(total_files * ratio)\n",
    "    selected_files = files[:number_of_files_to_load]\n",
    "    selected_files.sort(key=lambda f: int(re.search(f\"{IMG_NAME}_(\\d+).png\", f).group(1)))\n",
    "\n",
    "    images = []\n",
    "    use_list = []\n",
    "\n",
    "    for file in selected_files:\n",
    "        index = int(re.sub(r\"\\D\", \"\", file))\n",
    "        use_list.append(index)\n",
    "        img = Image.open(os.path.join(folder_path, file))\n",
    "        if convert_gray:\n",
    "            img = img.convert(\"L\")\n",
    "        if resize:\n",
    "            img = img.resize((m, m))\n",
    "        img_array = np.asarray(img).flatten()\n",
    "        img_array = img_array / 255\n",
    "        images.append(img_array)\n",
    "\n",
    "    return np.column_stack(images), use_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_1st_term(g, X, h):\n",
    "    print(\"calculate_1st_term start\")\n",
    "    return cp.linalg.norm(g - mult_mass(X, h)) ** 2\n",
    "\n",
    "def calculate_2nd_term(H):\n",
    "    print(\"calculate_2nd_term start\")\n",
    "    column_sums = cp.sum(cp.abs(H), axis=1)\n",
    "    result = cp.sum(column_sums**2)\n",
    "    return result\n",
    "\n",
    "\n",
    "def calculate_3rd_term(h):\n",
    "    print(\"calculate_3rd_term start\")\n",
    "    Du = mult_Dijkl(h)\n",
    "    tv = cp.sum(\n",
    "        cp.sqrt(\n",
    "            (Du[0 : M * N]) ** 2\n",
    "            + (Du[M * N : 2 * M * N]) ** 2\n",
    "            + (Du[2 * M * N : 3 * M * N]) ** 2\n",
    "            + (Du[3 * M * N :]) ** 2\n",
    "        )\n",
    "    )\n",
    "    print(\"calculate_3rd_term end\")\n",
    "    return tv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prox_l1(y: cp.ndarray, tau: float) -> cp.ndarray:\n",
    "    return cp.sign(y) * cp.maximum(cp.absolute(y) - tau, 0)\n",
    "\n",
    "\n",
    "def prox_l122(y: cp.ndarray, gamma: float) -> cp.ndarray:\n",
    "    H = y.reshape(M, N, order=\"F\")\n",
    "    row_norms = cp.linalg.norm(H, ord=1, axis=1, keepdims=True)\n",
    "    scaling_factors = cp.maximum(1 - gamma / (row_norms + 1e-8), 0)\n",
    "    H_prox = H * scaling_factors\n",
    "    return H_prox.ravel(order=\"F\")\n",
    "\n",
    "\n",
    "# def prox_l122(y: cp.ndarray, gamma: float) -> cp.ndarray:\n",
    "#     l1_norms = cp.sum(cp.absolute(vector2matrixCp(y, M, N)), axis=1)\n",
    "#     factor = (2 * gamma) / (1 + 2 * gamma * N)\n",
    "#     X = cp.sign(vector2matrixCp(y, M, N)) * cp.maximum(\n",
    "#         cp.absolute(vector2matrixCp(y, M, N)) - factor * l1_norms[:, None], 0\n",
    "#     )\n",
    "#     return matrix2vectorCp(X)\n",
    "\n",
    "\n",
    "def prox_tv(y: cp.ndarray, gamma: float) -> cp.ndarray:\n",
    "    Dx_norm = cp.linalg.norm(y.reshape(-1, 4, order=\"F\"), axis=1).astype(cp.float16)\n",
    "    Dx_norm = cp.tile(Dx_norm[:, None], (1, 4))\n",
    "    return (cp.maximum(1 - gamma / Dx_norm, 0) * y.reshape(-1, 4, order=\"F\")).reshape(-1, order=\"F\")\n",
    "\n",
    "\n",
    "def prox_conj(prox: Callable[[cp.ndarray, float], cp.ndarray], x: cp.ndarray, gamma: float) -> cp.ndarray:\n",
    "    \"\"\"Conjugate proximal operator.\"\"\"\n",
    "    return x - gamma * prox(x / gamma, 1 / gamma)\n",
    "\n",
    "\n",
    "def primal_dual_splitting(\n",
    "    X: cp.ndarray, g: cp.ndarray, lambda1: float, lambda2: float, max_iter: int = ITER\n",
    ") -> tuple[np.ndarray, dict]:\n",
    "    \"\"\"\n",
    "    Solve the optimization problem:\n",
    "    min_h ||g-Xh||_2^2 + lambda1 P(h) + lambda2 ||Dh||_{1,2}\n",
    "    using the primal-dual splitting method.\n",
    "\n",
    "    Args:\n",
    "        X (cp.ndarray): Matrix X in the problem formulation.\n",
    "        g (cp.ndarray): Vector g in the problem formulation.\n",
    "        lambda1 (float): Regularization parameter for L1 norm of h.\n",
    "        lambda2 (float): Regularization parameter for L1 norm of Dh.\n",
    "\n",
    "    Returns:\n",
    "        tuple[np.ndarray, dict]: Solution h and a dictionary containing additional information.\n",
    "    \"\"\"\n",
    "\n",
    "    with cp.cuda.Device(X.device.id):\n",
    "        h = cp.zeros((M * N,), dtype=cp.float16)\n",
    "        # h = cp.ndarray((M * N,), dtype=cp.float16, memptr=cp.cuda.malloc_managed(M * N * 2))\n",
    "        h_old = cp.zeros_like(h)\n",
    "        # h_old = cp.ndarray((M * N,), dtype=cp.float16, memptr=cp.cuda.malloc_managed(M * N * 2))\n",
    "        print(f\"h GPU memory usage: {h.nbytes / 1024**2} MB\")\n",
    "        print(f\"h_old GPU memory usage: {h_old.nbytes / 1024**2} MB\")\n",
    "\n",
    "    with cp.cuda.Device(g.device.id):\n",
    "        y = cp.zeros((4 * M * N,), dtype=cp.float16)\n",
    "        # y = cp.ndarray((4 * M * N,), dtype=cp.float16, memptr=cp.cuda.malloc_managed(4 * M * N * 2))\n",
    "        y_old = cp.zeros_like(y)\n",
    "        # y_old = cp.ndarray((4 * M * N,), dtype=cp.float16, memptr=cp.cuda.malloc_managed(4 * M * N * 2))\n",
    "        print(f\"y GPU memory usage: {y.nbytes / 1024**2} MB\")\n",
    "        print(f\"y_old GPU memory usage: {y_old.nbytes / 1024**2} MB\")\n",
    "\n",
    "    # memptr_D = cp.cuda.malloc_managed(4 * M * N * 2)\n",
    "    # memptr_DT = cp.cuda.malloc_managed(M * N * 2)\n",
    "\n",
    "    h[:] = 1e-5\n",
    "    h_old[:] = 0\n",
    "    y[:] = 1e-5\n",
    "    y_old[:] = 0\n",
    "\n",
    "    # Compute Lipschitz constant of grad_f\n",
    "    tau = 1e-4\n",
    "    sigma = 1e-2\n",
    "    print(f\"tau={tau}, sigma={sigma}\")\n",
    "\n",
    "    # start = time.perf_counter()\n",
    "    for k in range(max_iter):\n",
    "        h_old[:] = h[:]\n",
    "        y_old[:] = y[:]\n",
    "\n",
    "        h[:] = prox_l122(\n",
    "            h_old - tau * (mult_mass(X.T, (mult_mass(X, h_old) - g)) - mult_DijklT(y_old)),\n",
    "            tau * lambda1,\n",
    "        )\n",
    "\n",
    "        y[:] = prox_conj(prox_tv, y_old + sigma * mult_Dijkl(2 * h - h_old), sigma * lambda2)\n",
    "\n",
    "        # calculate 2nd term & 3rd term\n",
    "        if k % 50 == 49:\n",
    "            print(\"1st\", calculate_1st_term(g, X, h))\n",
    "            print(\"2nd\", calculate_2nd_term(vector2matrixCp(h, M, N)))\n",
    "            print(\"3rd\", calculate_3rd_term(h))\n",
    "            primal_residual = cp.linalg.norm(h - h_old) / cp.linalg.norm(h)\n",
    "            dual_residual = cp.linalg.norm(y - y_old) / cp.linalg.norm(y)\n",
    "            print(f\"iter={k}, primal_res={primal_residual:.8f}, dual_res={dual_residual:.8f}\")\n",
    "            if primal_residual < 1e-3 and dual_residual < 1e-3:\n",
    "                break\n",
    "\n",
    "        if k == max_iter - 1:\n",
    "            primal_residual = cp.linalg.norm(h - h_old) / cp.linalg.norm(h)\n",
    "            dual_residual = cp.linalg.norm(y - y_old) / cp.linalg.norm(y)\n",
    "            print(f\"iter={k}, primal_res={primal_residual:.8f}, dual_res={dual_residual:.8f}\")\n",
    "            break\n",
    "        else:\n",
    "            print(f\"iter={k}\")\n",
    "\n",
    "    # end = time.perf_counter()\n",
    "    info = {\n",
    "        \"iterations\": k + 1,\n",
    "        \"primal_residual\": primal_residual,\n",
    "        \"dual_residual\": dual_residual,\n",
    "        # \"time\": end - start,\n",
    "    }\n",
    "\n",
    "    return cp.asnumpy(h), info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images\n",
    "INFO = \"cap_240814\"\n",
    "G, use = images_to_matrix(f\"{DATA_PATH}/{IMG_NAME}{n}_{INFO}/\", resize=True)\n",
    "F, _ = images_to_matrix(f\"{DATA_PATH}/{IMG_NAME}{n}_input/\")\n",
    "print(\"K=\", F.shape[1])\n",
    "white_img = Image.open(f\"{DATA_PATH}/{IMG_NAME}{n}_{INFO}/{IMG_NAME}_1.png\").convert(\"L\")\n",
    "white_img = white_img.resize((m, m))\n",
    "white = np.asarray(white_img).flatten() / 255\n",
    "white = white[:, np.newaxis]\n",
    "H1 = np.tile(white, F.shape[1])\n",
    "F_hat = 2 * F - 1\n",
    "G_hat = 2 * G - H1\n",
    "\n",
    "g = matrix2vectorNp(G_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_hat_T_gpu = cp.asarray(F_hat.T).astype(cp.int8)\n",
    "g_gpu = cp.asarray(g).astype(cp.float16)\n",
    "\n",
    "print(f\"F device: {F_hat_T_gpu.device}\")\n",
    "print(f\"g device: {g_gpu.device}\")\n",
    "del F, G, H1, F_hat, G_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, info = primal_dual_splitting(F_hat_T_gpu, g_gpu, LAMBDA1, LAMBDA2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = vector2matrixNp(h, M, N)\n",
    "np.save(f\"{DIRECTORY}/systemMatrix/H_matrix_{SETTING}.npy\", H)\n",
    "print(f\"Saved {DIRECTORY}/systemMatrix/H_matrix_{SETTING}.npy\")\n",
    "\n",
    "SAMPLE_NAME = \"Cameraman\"\n",
    "sample_image = Image.open(f\"{DATA_PATH}/sample_image{n}/{SAMPLE_NAME}.png\").convert('L')\n",
    "sample_image = np.asarray(sample_image).flatten() / 255\n",
    "\n",
    "Hf = H @ sample_image\n",
    "Hf_img = Hf.reshape(m, m)\n",
    "Hf_img = np.clip(Hf_img, 0, 1)\n",
    "Hf_pil = Image.fromarray((Hf_img * 255).astype(np.uint8), mode='L')\n",
    "\n",
    "FILENAME = f\"{SAMPLE_NAME}_{SETTING}.png\"\n",
    "fig, ax = plt.subplots(figsize=Hf_img.shape[::-1], dpi=1, tight_layout=True)\n",
    "ax.imshow(Hf_pil, cmap='gray')\n",
    "ax.axis('off')\n",
    "fig.savefig(f\"{DIRECTORY}/{FILENAME}\", dpi=1)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "import cupyx.scipy.sparse as csp\n",
    "import cupyx.scipy.sparse.linalg as csla\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from typing import List\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from IPython.display import display\n",
    "import package.myUtil as myUtil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_dates = {128: \"241114\", 256: \"241205\"}\n",
    "n = 256\n",
    "LAMBDA = 100\n",
    "RATIO = 0.05\n",
    "DO_THIN_OUT = False\n",
    "SAVE_AS_SPARSE = True\n",
    "DATA_PATH = \"../data\"\n",
    "IMG_NAME = \"hadamard\"\n",
    "CAP_DATE = cap_dates[n]\n",
    "EXP_DATE = \"241206\"\n",
    "DIRECTORY = f\"{DATA_PATH}/{EXP_DATE}\"\n",
    "SETTING = f\"{n}_p-{int(100*RATIO)}_lmd-{LAMBDA}\"\n",
    "if DO_THIN_OUT:\n",
    "    SETTING = SETTING + \"to\"\n",
    "\n",
    "if not os.path.exists(DIRECTORY):\n",
    "    os.makedirs(DIRECTORY)\n",
    "if not os.path.exists(DIRECTORY + \"/systemMatrix\"):\n",
    "    os.makedirs(DIRECTORY + \"/systemMatrix\")\n",
    "use_list = myUtil.get_use_list(n * n, RATIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = myUtil.images2matrix(f\"{DATA_PATH}/{IMG_NAME}{n}_cap_{CAP_DATE}/\", use_list, thin_out=DO_THIN_OUT)\n",
    "F = myUtil.images2matrix(f\"{DATA_PATH}/{IMG_NAME}{n}_input/\", use_list).astype(cp.int8)\n",
    "M, K = G.shape\n",
    "N, K = F.shape\n",
    "print(\"G shape:\", G.shape, \"F shape:\", F.shape, \"M=\", M, \"N=\", N, \"K=\", K)\n",
    "print(\"G max:\", G.max(), \"G min:\", G.min(), \"F max:\", F.max(), \"F min:\", F.min())\n",
    "\n",
    "black = myUtil.calculate_bias(M, DATA_PATH, CAP_DATE)\n",
    "B = cp.tile(black[:, None], K)\n",
    "\n",
    "G = G - B\n",
    "\n",
    "white_img = Image.open(f\"{DATA_PATH}/capture_{CAP_DATE}/White.png\").convert(\"L\")\n",
    "white = (cp.asarray(white_img) / 255).astype(cp.float32)\n",
    "if DO_THIN_OUT:\n",
    "    white = white[::2, ::2].ravel() - black\n",
    "else:\n",
    "    white = white.ravel() - black\n",
    "H1 = cp.tile(white[:, None], K)\n",
    "\n",
    "F_hat = 2 * F - 1\n",
    "G_hat = 2 * G - H1\n",
    "del F, G, H1\n",
    "cp._default_memory_pool.free_all_blocks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prox_l122(Y: cp.ndarray, gamma: float, N: int) -> csp.csr_matrix:\n",
    "    factor = (2 * gamma) / (1 + 2 * gamma * N)\n",
    "    l1_norms = cp.sum(cp.abs(Y), axis=1)\n",
    "    X = cp.sign(Y) * cp.maximum(cp.abs(Y) - factor * l1_norms[:, None], 0)\n",
    "    return csp.csr_matrix(X)\n",
    "\n",
    "\n",
    "def process_chunk(\n",
    "    F: cp.ndarray, G: cp.ndarray, lmd: float, N: int, start: int, end: int, gamma: float, max_iter: int, device_id: int\n",
    ") -> csp.csr_matrix:\n",
    "    with cp.cuda.Device(device_id):\n",
    "        chunk_size = end - start\n",
    "        t = 1.0\n",
    "        H_chunk = csp.csr_matrix((chunk_size, N), dtype=cp.float32)\n",
    "        Y_chunk = cp.zeros((chunk_size, N), dtype=cp.float32)\n",
    "\n",
    "        for i in range(max_iter):\n",
    "            t_old = t\n",
    "            H_chunk_old = H_chunk.copy()\n",
    "\n",
    "            gradient = (Y_chunk @ F - G[start:end, :]) @ F.T\n",
    "            prox_input = Y_chunk - gamma * gradient\n",
    "            H_chunk = prox_l122(prox_input, gamma * lmd, N)\n",
    "            t = (1 + cp.sqrt(1 + 4 * t_old**2)) / 2\n",
    "            Y_chunk = H_chunk + ((t_old - 1) / t) * (H_chunk - H_chunk_old)\n",
    "\n",
    "        cp.get_default_memory_pool().free_all_blocks()\n",
    "        return H_chunk\n",
    "\n",
    "\n",
    "def fista_multi_gpu(\n",
    "    F: cp.ndarray,\n",
    "    G: cp.ndarray,\n",
    "    lmd: float,\n",
    "    N: int,\n",
    "    M: int,\n",
    "    chunk_size: int = 2000,\n",
    "    max_iter: int = 150,\n",
    "    device_ids: List[int] = [0, 2],\n",
    ") -> cp.ndarray:\n",
    "    \"\"\"\n",
    "    Solve the optimization problem using FISTA with multi-GPU support:\n",
    "    min_h ||G - HF||_F^2 + lambda * ||H||_1,2^2\n",
    "    \"\"\"\n",
    "    # Lipschitz constant\n",
    "    L = N\n",
    "    print(\"L:\", L)\n",
    "    gamma = 1.0 / (L * 3)\n",
    "\n",
    "    chunks: List[csp.csr_matrix] = []\n",
    "\n",
    "    # すべてのchunkのインデックスを作成\n",
    "    chunk_indices = [(c * chunk_size, min((c + 1) * chunk_size, M)) for c in range(math.ceil(M / chunk_size))]\n",
    "\n",
    "    def worker(start_end_device):\n",
    "        start, end, device_id = start_end_device\n",
    "        return process_chunk(F, G, lmd, N, start, end, gamma, max_iter, device_id)\n",
    "\n",
    "    # 各chunkに対してGPUを割り当てる（ラウンドロビン方式）\n",
    "    chunk_assignments = [(start, end, device_ids[c % len(device_ids)]) for c, (start, end) in enumerate(chunk_indices)]\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=len(device_ids)) as executor:\n",
    "        for H_chunk in executor.map(worker, chunk_assignments):\n",
    "            chunks.append(H_chunk)\n",
    "\n",
    "    # すべてのGPUから集約するために、メインGPU（例えばGPU 0）に移動\n",
    "    with cp.cuda.Device(device_ids[0]):\n",
    "        H = csp.vstack(chunks).tocsr()\n",
    "\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = fista_multi_gpu(F_hat, G_hat, LAMBDA, N, M)\n",
    "print(\"H shape:\", H.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE_AS_SPARSE:\n",
    "    print(f\"shape: {H.shape}, nnz: {H.nnz}({H.nnz / H.shape[0] / H.shape[1] * 100:.2f}%)\")\n",
    "    H_np = {\n",
    "        \"data\": cp.asnumpy(H.data),\n",
    "        \"indices\": cp.asnumpy(H.indices),\n",
    "        \"indptr\": cp.asnumpy(H.indptr),\n",
    "        \"shape\": H.shape\n",
    "    }\n",
    "    np.savez(f\"{DIRECTORY}/systemMatrix/H_matrix_{SETTING}.npz\", **H_np)\n",
    "    print(f\"Saved {DIRECTORY}/systemMatrix/H_matrix_{SETTING}.npz\")\n",
    "    # myUtil.plot_sparse_matrix_cupy(H, row_range=(5500, 6000), col_range=(4500, 5000), markersize=1)\n",
    "else:\n",
    "    cp.save(f\"{DIRECTORY}/systemMatrix/H_matrix_{SETTING}.npy\", H)\n",
    "    print(f\"Saved {DIRECTORY}/systemMatrix/H_matrix_{SETTING}.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_NAME = \"Cameraman\"\n",
    "sample_image = Image.open(f\"{DATA_PATH}/sample_image{n}/{SAMPLE_NAME}.png\").convert(\"L\")\n",
    "sample_image = cp.asarray(sample_image).flatten() / 255\n",
    "\n",
    "m = int(math.sqrt(M))\n",
    "FILENAME = f\"{SAMPLE_NAME}_{SETTING}.png\"\n",
    "Hf = H @ sample_image + black\n",
    "Hf = cp.asnumpy(Hf.reshape(m, m))\n",
    "print(\"Hf shape:\", Hf.shape)\n",
    "\n",
    "Hf_pil = Image.fromarray((Hf * 255).astype(np.uint8), mode=\"L\")\n",
    "Hf_pil.save(f\"{DIRECTORY}/{FILENAME}\", format='PNG')\n",
    "print(f\"Saved {DIRECTORY}/{FILENAME}\")\n",
    "display(Hf_pil)\n",
    "\n",
    "plt.imshow(Hf, cmap='gray', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.title('Grayscale Heatmap')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

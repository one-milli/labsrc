{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "# import tensorflow as tf\n",
    "import cv2\n",
    "import scipy.sparse as ssp\n",
    "from scipy import ndimage\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_points_with_masks(frame):\n",
    "    \"\"\"\n",
    "    フレームから白い点を検出し、それぞれの点に対応するマスク（輝度分布）を取得する。\n",
    "    \n",
    "    Parameters:\n",
    "        frame (ndarray): 入力フレーム（2D配列）。\n",
    "    \n",
    "    Returns:\n",
    "        centers (ndarray): 各点の重心座標の配列（形状: (N, 2)）。\n",
    "        masks (list of ndarray): 各点のマスク（輝度分布を含む、形状: (H, W)）。\n",
    "    \"\"\"\n",
    "    binary = (frame >= 0).astype(np.uint8)\n",
    "    \n",
    "    # 点のラベリング\n",
    "    labeled, num_features = ndimage.label(binary)\n",
    "    \n",
    "    centers = []\n",
    "    masks = []\n",
    "    \n",
    "    for i in range(1, num_features + 1):\n",
    "        mask = (labeled == i).astype(np.float32)\n",
    "        min_pixels = 2\n",
    "        if np.sum(mask) < min_pixels:\n",
    "            continue  # 小さすぎる点は無視\n",
    "        \n",
    "        # 元のフレームの輝度をマスク\n",
    "        mask_with_brightness = mask * frame\n",
    "        \n",
    "        # 重心の計算\n",
    "        center = ndimage.center_of_mass(mask)\n",
    "        centers.append(center)\n",
    "        masks.append(mask_with_brightness)\n",
    "    \n",
    "    centers = np.array(centers)  # 形状: (N, 2)\n",
    "    return centers, masks\n",
    "\n",
    "def compute_motion_vectors(prev_centers, next_centers, max_distance=10):\n",
    "    \"\"\"\n",
    "    各点の動きベクトルを計算する。\n",
    "    最も近い点を対応付けとして動きベクトルを計算する。\n",
    "    \n",
    "    Parameters:\n",
    "        prev_centers (ndarray): 前のフレームの点の重心座標（形状: (N, 2)）。\n",
    "        next_centers (ndarray): 次のフレームの点の重心座標（形状: (M, 2)）。\n",
    "        max_distance (float): 対応付けを許容する最大距離。\n",
    "    \n",
    "    Returns:\n",
    "        motion_vectors (ndarray): 各前フレームの点に対応する動きベクトル（形状: (N, 2)）。\n",
    "        matched_next_indices (list): 各前フレームの点に対応する次フレームの点のインデックス。対応がない場合はNone。\n",
    "    \"\"\"\n",
    "    motion_vectors = []\n",
    "    matched_next_indices = []\n",
    "    used_next = set()\n",
    "    \n",
    "    # next_centersが空の場合、すべての動きベクトルをゼロに\n",
    "    if next_centers.size == 0:\n",
    "        for _ in prev_centers:\n",
    "            motion_vectors.append([0.0, 0.0])\n",
    "            matched_next_indices.append(None)\n",
    "        return np.array(motion_vectors), matched_next_indices\n",
    "    \n",
    "    for p in prev_centers:\n",
    "        distances = np.linalg.norm(next_centers - p, axis=1)\n",
    "        min_idx = np.argmin(distances)\n",
    "        min_dist = distances[min_idx]\n",
    "        \n",
    "        if min_dist <= max_distance and min_idx not in used_next:\n",
    "            used_next.add(min_idx)\n",
    "            vector = next_centers[min_idx] - p  # (dy, dx)\n",
    "            matched_next_indices.append(min_idx)\n",
    "        else:\n",
    "            vector = np.array([0.0, 0.0])  # 対応が見つからない場合は動かない\n",
    "            matched_next_indices.append(None)\n",
    "        \n",
    "        motion_vectors.append(vector)\n",
    "    \n",
    "    return np.array(motion_vectors), matched_next_indices  # 形状: (N, 2), list of matched indices or None\n",
    "\n",
    "def interpolate_masks(current_masks, next_masks, motion_vectors, matched_next_indices, alpha, frame_shape):\n",
    "    \"\"\"\n",
    "    各点のマスクを補間位置に移動させて新しいマスクを生成する。\n",
    "    各点について、前フレームのマスクを1/2動きベクトル分移動させ、\n",
    "    次フレームのマスクを-1/2動きベクトル分移動させたものをブレンドする。\n",
    "    \n",
    "    Parameters:\n",
    "        current_masks (list of ndarray): 前のフレームのマスク（輝度分布）。\n",
    "        next_masks (list of ndarray): 次のフレームのマスク（輝度分布）。\n",
    "        motion_vectors (ndarray): 各点の動きベクトル（形状: (N, 2)）。\n",
    "        matched_next_indices (list): 各前フレームの点に対応する次フレームの点のインデックス。対応がない場合はNone。\n",
    "        alpha (float): 補間係数（通常は0.5）。\n",
    "        frame_shape (tuple): 補間フレームの形状（高さ, 幅）。\n",
    "    \n",
    "    Returns:\n",
    "        interp_frame (ndarray): 補間フレーム（2D配列）。\n",
    "    \"\"\"\n",
    "    interp_frame = np.zeros(frame_shape, dtype=np.float32)\n",
    "    num_points = len(current_masks)\n",
    "    \n",
    "    for i in range(num_points):\n",
    "        vector = motion_vectors[i]\n",
    "        half_vector = vector * 0.5\n",
    "        \n",
    "        # 前フレームのマスクを1/2動きベクトル分移動\n",
    "        M_current = np.float32([[1, 0, half_vector[1]], [0, 1, half_vector[0]]])  # [ [1, 0, dx], [0, 1, dy] ]\n",
    "        shifted_current = cv2.warpAffine(current_masks[i], M_current, (frame_shape[1], frame_shape[0]),\n",
    "                                            flags=cv2.INTER_LINEAR, borderValue=0)\n",
    "        \n",
    "        # 次フレームのマスクを-1/2動きベクトル分移動\n",
    "        if matched_next_indices[i] is not None and matched_next_indices[i] < len(next_masks):\n",
    "            next_mask = next_masks[matched_next_indices[i]]\n",
    "            M_next = np.float32([[1, 0, -half_vector[1]], [0, 1, -half_vector[0]]])\n",
    "            shifted_next = cv2.warpAffine(next_mask, M_next, (frame_shape[1], frame_shape[0]),\n",
    "                                            flags=cv2.INTER_LINEAR, borderValue=0)\n",
    "        else:\n",
    "            # 対応する次フレームのマスクがない場合はゼロマスクを使用\n",
    "            shifted_next = np.zeros(frame_shape, dtype=np.float32)\n",
    "        \n",
    "        # マスクのブレンド（平均）\n",
    "        blended_mask = (shifted_current + shifted_next) / 2.0\n",
    "        \n",
    "        # 補間フレームに加算\n",
    "        interp_frame += blended_mask\n",
    "    \n",
    "    return interp_frame\n",
    "\n",
    "def interpolate_frames(frames, num_interpolations=1):\n",
    "    \"\"\"\n",
    "    フレーム補間を行う。\n",
    "    各フレーム間に指定された数の補間フレームを挿入する。\n",
    "    \n",
    "    Parameters:\n",
    "        frames (ndarray): 元のフレーム配列（形状: (num_frames, H, W)）。\n",
    "        num_interpolations (int): 各フレーム間に挿入する補間フレームの数。\n",
    "    \n",
    "    Returns:\n",
    "        interpolated (ndarray): 補間後のフレーム配列（形状: new_num_frames, H, W）。\n",
    "    \"\"\"\n",
    "    interpolated = []\n",
    "    num_frames = frames.shape[0]\n",
    "    height, width = frames[0].shape\n",
    "    \n",
    "    for t in range(num_frames - 1):\n",
    "        current_frame = frames[t]\n",
    "        next_frame = frames[t + 1]\n",
    "        \n",
    "        # 点の検出とマスクの取得\n",
    "        current_centers, current_masks = detect_points_with_masks(current_frame)\n",
    "        next_centers, next_masks = detect_points_with_masks(next_frame)\n",
    "        \n",
    "        # 動きベクトルの計算と対応付けの取得\n",
    "        motion_vectors, matched_next_indices = compute_motion_vectors(current_centers, next_centers)\n",
    "        \n",
    "        # 現在のフレームを追加\n",
    "        # interpolated.append(current_frame)\n",
    "        \n",
    "        # 点が存在しない場合の処理\n",
    "        if len(current_centers) == 0 or len(next_centers) == 0:\n",
    "            # 補間フレームとして黒いフレームを追加\n",
    "            for k in range(1, num_interpolations + 1):\n",
    "                interp_frame = np.zeros((height, width), dtype=np.float32)\n",
    "                interpolated.append(interp_frame)\n",
    "            continue\n",
    "        \n",
    "        # 各補間フレームの生成\n",
    "        for k in range(1, num_interpolations + 1):\n",
    "            # 補間係数（通常は0.5）\n",
    "            alpha = k / (num_interpolations + 1)\n",
    "            \n",
    "            # 補間フレームの生成\n",
    "            interp_frame = interpolate_masks(current_masks, next_masks, motion_vectors, matched_next_indices, alpha, (height, width))\n",
    "            \n",
    "            interpolated.append(interp_frame)\n",
    "    \n",
    "    # 最後のフレームを追加\n",
    "    # interpolated.append(frames[-1])\n",
    "    return np.array(interpolated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_to_tensor(H, m, n):\n",
    "    return H.reshape(m, m, n, n)\n",
    "\n",
    "\n",
    "def tensor_to_matrix(tensor, m, n):\n",
    "    return tensor.reshape(m * m, n * n)\n",
    "\n",
    "\n",
    "n = 128\n",
    "_m = 128\n",
    "# DATA_PATH = \"../../OneDrive - m.titech.ac.jp/Lab/data\"\n",
    "DATA_PATH = \"../data\"\n",
    "EXP_DATE = \"241105\"\n",
    "H_SETTING = \"p-5_lmd-100_m-128\"\n",
    "H_mat = np.load(f\"{DATA_PATH}/{EXP_DATE}/systemMatrix/H_matrix_{H_SETTING}.npy\")\n",
    "print(\"H shape:\", H_mat.shape, \"type(H):\", type(H_mat), \"H.dtype:\", H_mat.dtype)\n",
    "# しきい値処理\n",
    "H_mat[np.abs(H_mat) < 0.01] = 0\n",
    "H_ten = matrix_to_tensor(H_mat, _m, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# フレーム補間\n",
    "m = 2 * _m - 1  # 255\n",
    "interpolated_tensor = np.zeros((m, m, n, n), dtype=np.float32)\n",
    "for i in range(0, m, 2):\n",
    "    frames = H_ten[i // 2, :, :, :]\n",
    "    interpolated_frames = interpolate_frames(frames)\n",
    "    for j in range(m):\n",
    "        if j % 2 == 0:\n",
    "            interpolated_tensor[i, j, :, :] = H_ten[i // 2, j // 2, :, :]\n",
    "        else:\n",
    "            interpolated_tensor[i, j, :, :] = interpolated_frames[j // 2, :, :]\n",
    "for j in range(0, m):\n",
    "    frames = interpolated_tensor[::2, j, :, :]\n",
    "    interpolated_frames = interpolate_frames(frames)\n",
    "    for i in range(1, m, 2):\n",
    "        interpolated_tensor[i, j, :, :] = interpolated_frames[i // 2, :, :]\n",
    "\n",
    "print(\"interpolated_tensor.shape:\", interpolated_tensor.shape, \"dtype:\", interpolated_tensor.dtype)\n",
    "interpolated_matrix = tensor_to_matrix(interpolated_tensor, m, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f\"{DATA_PATH}/{EXP_DATE}/systemMatrix/H_matrix_int_{H_SETTING}.npy\", interpolated_matrix)\n",
    "print(f\"Saved {DATA_PATH}/{EXP_DATE}/systemMatrix/H_matrix_int_{H_SETTING}.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_NAME = \"Cameraman\"\n",
    "sample_image = Image.open(f\"{DATA_PATH}/sample_image{n}/{SAMPLE_NAME}.png\").convert(\"L\")\n",
    "sample_image = np.asarray(sample_image).flatten() / 255\n",
    "\n",
    "Hf = interpolated_matrix @ sample_image\n",
    "# Hf_img = Hf.reshape(m, m)\n",
    "Hf_img = np.asnumpy(Hf.reshape(m, m), Image.resampling.BICUBIC)\n",
    "Hf_img = np.clip(Hf_img, 0, 1)\n",
    "print(\"Hf shape:\", Hf_img.shape)\n",
    "Hf_pil = Image.fromarray((Hf_img * 255).astype(np.uint8), mode=\"L\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=Hf_img.shape[::-1], dpi=1, tight_layout=True)\n",
    "ax.imshow(Hf_pil, cmap=\"gray\")\n",
    "ax.axis(\"off\")\n",
    "plt.show()\n",
    "FILENAME = f\"{SAMPLE_NAME}_{H_SETTING}.png\"\n",
    "# fig.savefig(f\"{DIRECTORY}/{FILENAME}\", dpi=1)\n",
    "# print(f\"Saved {DIRECTORY}/{FILENAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = 128\n",
    "interpolated_frames = interpolated_tensor[:, J, :, :]\n",
    "print(\"interpolated_frames.shape:\", interpolated_frames.shape)\n",
    "# 表示したいフレームの範囲を設定\n",
    "start_index = 60\n",
    "end_index = 84\n",
    "frames_to_display = interpolated_frames[start_index:end_index + 1]\n",
    "\n",
    "num_frames = len(frames_to_display)\n",
    "cols = 5  # 列数を設定（必要に応じて変更可能）\n",
    "rows = math.ceil(num_frames / cols)  # 行数を自動計算\n",
    "\n",
    "# サブプロットを作成\n",
    "fig, axs = plt.subplots(rows, cols, figsize=(5 * cols, 5 * rows))\n",
    "\n",
    "# サブプロットの軸を1次元にフラット化してループ処理\n",
    "for idx, ax in enumerate(axs.flat):\n",
    "    if idx < num_frames:\n",
    "        frame = frames_to_display[idx]\n",
    "        img = ax.imshow(frame, cmap='gray')\n",
    "        plt.colorbar(img, ax=ax)\n",
    "        ax.set_title(f'Frame {start_index + idx}')\n",
    "    else:\n",
    "        ax.axis('off')  # 使用しないサブプロットを非表示に"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import io\n",
    "\n",
    "def create_heatmap_gif(data, output_path, duration=0.5):\n",
    "    \"\"\"\n",
    "    m×n×nのnumpy配列をヒートマップのGIFに変換する。\n",
    "\n",
    "    Parameters:\n",
    "    - data: ndarray, shape (m, n, n)\n",
    "    - output_path: str, 保存するGIFのパス\n",
    "    - duration: float, 各フレームの表示時間（秒）\n",
    "    \"\"\"\n",
    "    # データが3次元か確認\n",
    "    if data.ndim != 3:\n",
    "        raise ValueError(\"入力データは3次元のnumpy配列である必要があります。\")\n",
    "\n",
    "    m, n1, n2 = data.shape\n",
    "    if n1 != n2:\n",
    "        raise ValueError(\"各スライスはn×nの形状である必要があります。\")\n",
    "\n",
    "    # テンソルの最大値と最小値を計算\n",
    "    vmin = np.min(data)\n",
    "    vmax = np.max(data)\n",
    "\n",
    "    images = []  # GIFに追加する画像のリスト\n",
    "\n",
    "    # 図と軸を設定\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    # plt.axis('off')  # 軸を非表示\n",
    "\n",
    "    # ヒートマップを初期化\n",
    "    cax = ax.imshow(data[0], cmap='gray', vmin=vmin, vmax=vmax)\n",
    "    # カラーバーを一度だけ追加\n",
    "    cbar = fig.colorbar(cax, ax=ax, fraction=0.046, pad=0.04)\n",
    "    cbar.ax.tick_params(labelsize=8)\n",
    "    title = ax.set_title(f'Frame 1/{m}', fontsize=10)\n",
    "\n",
    "    for i in range(m):\n",
    "        # ヒートマップのデータを更新\n",
    "        cax.set_data(data[i])\n",
    "        # タイトルを更新\n",
    "        title.set_text(f'Frame {i+1}/{m}')\n",
    "\n",
    "        # レイアウトを固定\n",
    "        fig.tight_layout()\n",
    "\n",
    "        # 画像をバッファに保存\n",
    "        buf = io.BytesIO()\n",
    "        plt.savefig(buf, format='png')\n",
    "        buf.seek(0)\n",
    "        image = imageio.v2.imread(buf)\n",
    "        images.append(image)\n",
    "        buf.close()\n",
    "\n",
    "    plt.close(fig)  # 図を閉じる\n",
    "\n",
    "    # GIFとして保存\n",
    "    imageio.mimsave(output_path, images, duration=duration)\n",
    "    print(f\"GIFが保存されました: {output_path}\")\n",
    "\n",
    "create_heatmap_gif(interpolated_frames, f\"{DATA_PATH}/{EXP_DATE}/interpolated_j{J}_video.gif\", duration=0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最適化問題\n",
    "\n",
    "$$ \\min_h \\|\\bm{g}-F^\\top \\bm{h}\\|_2^2+\\lambda_1\\|\\bm{h}\\|_{1,2}^2 + \\lambda_2\\|D\\bm{h}\\|_{1,2}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "from typing import Callable\n",
    "import cupy as cp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パラメータ設定\n",
    "n = 64\n",
    "m = 128\n",
    "N = n**2\n",
    "M = m**2\n",
    "LAMBDA1 = 10\n",
    "LAMBDA2 = 1\n",
    "SEED = 3\n",
    "RATIO = 0.1\n",
    "ITER = 500\n",
    "DATA_PATH = \"../../OneDrive - m.titech.ac.jp/Lab/data\"\n",
    "IMG_NAME = \"hadamard\"\n",
    "DIRECTORY = DATA_PATH + \"/240724\"\n",
    "SETTING = f\"{IMG_NAME}_pr-du_p-{int(100*RATIO)}_lmd1-{LAMBDA1}_lmd2-{LAMBDA2}_iter-{ITER}\"\n",
    "\n",
    "if not os.path.exists(DIRECTORY):\n",
    "    os.makedirs(DIRECTORY)\n",
    "if not os.path.exists(DIRECTORY + \"/systemMatrix\"):\n",
    "    os.makedirs(DIRECTORY + \"/systemMatrix\")\n",
    "\n",
    "Di = sparse.eye(M, format='lil') - sparse.eye(M, k=m, format='lil')\n",
    "Di[-m:, :] = 0\n",
    "Di = Di.tocsr()\n",
    "\n",
    "Dj = sparse.eye(M, format='lil') - sparse.eye(M, k=1, format='lil')\n",
    "for p in range(1, m + 1):\n",
    "    Dj[m * p - 1, m * p - 1] = 0\n",
    "    if p < m:\n",
    "        Dj[m * p - 1, m * p] = 0\n",
    "Dj = Dj.tocsr()\n",
    "\n",
    "Dk = sparse.eye(N, format='lil') - sparse.eye(N, k=n, format='lil')\n",
    "Dk = sparse.lil_matrix(Dk[:n * (n - 1), :N])\n",
    "Dk = sparse.vstack([Dk, sparse.lil_matrix((n, N))])\n",
    "Dk = Dk.tocsr()\n",
    "\n",
    "Dl = sparse.eye(N, format='lil') - sparse.eye(N, k=1, format='lil')\n",
    "for p in range(1, n + 1):\n",
    "    Dl[n * p - 1, n * p - 1] = 0\n",
    "    if p < n:\n",
    "        Dl[n * p - 1, n * p] = 0\n",
    "Dl = Dl.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Di_gpu = cp.sparse.csr_matrix(Di).astype(cp.float32)\n",
    "Dj_gpu = cp.sparse.csr_matrix(Dj).astype(cp.float32)\n",
    "Dk_gpu = cp.sparse.csr_matrix(Dk).astype(cp.float32)\n",
    "Dl_gpu = cp.sparse.csr_matrix(Dl).astype(cp.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix2vectorNp(matrix: np.ndarray) -> np.ndarray:\n",
    "    return matrix.reshape(-1, 1, order=\"F\").flatten().astype(np.float32)\n",
    "\n",
    "\n",
    "def matrix2vectorCp(matrix: cp.ndarray) -> cp.ndarray:\n",
    "    return matrix.reshape(-1, 1, order=\"F\").flatten().astype(cp.float32)\n",
    "\n",
    "\n",
    "def vector2matrixNp(vector: np.ndarray, s: int, t: int) -> np.ndarray:\n",
    "    return vector.reshape(s, t, order=\"F\").astype(np.float32)\n",
    "\n",
    "\n",
    "def vector2matrixCp(vector: cp.ndarray, s: int, t: int) -> cp.ndarray:\n",
    "    return vector.reshape(s, t, order=\"F\").astype(cp.float32)\n",
    "\n",
    "\n",
    "def mult_mass(X: cp.ndarray, h: cp.ndarray, M: int) -> cp.ndarray:\n",
    "    F_gpu = X.T.astype(cp.float32)\n",
    "    H_gpu = cp.asarray(h.reshape(M, -1, order=\"F\"))\n",
    "    res_gpu = H_gpu @ F_gpu\n",
    "    return matrix2vectorCp(res_gpu)\n",
    "\n",
    "\n",
    "def mult_Dijkl(h: cp.ndarray) -> cp.ndarray:\n",
    "    H = vector2matrixCp(h, M, N)\n",
    "    res_gpu = cp.hstack([Di_gpu @ H, Dj_gpu @ H, H @ Dk_gpu.T, H @ Dl_gpu.T])\n",
    "    return matrix2vectorCp(res_gpu)\n",
    "\n",
    "\n",
    "def mult_DijklT(y: cp.ndarray) -> cp.ndarray:\n",
    "    y1 = y[: M * N]\n",
    "    y2 = y[M * N : 2 * M * N]\n",
    "    y3 = y[2 * M * N : 3 * M * N]\n",
    "    y4 = y[3 * M * N :]\n",
    "    Y1 = vector2matrixCp(y1, M, N)\n",
    "    Y2 = vector2matrixCp(y2, M, N)\n",
    "    Y3 = vector2matrixCp(y3, M, N)\n",
    "    Y4 = vector2matrixCp(y4, M, N)\n",
    "\n",
    "    res_gpu = Di_gpu.T @ Y1 + Dj_gpu.T @ Y2 + Y3 @ Dk_gpu.T + Y4 @ Dl_gpu.T\n",
    "    return matrix2vectorCp(res_gpu)\n",
    "\n",
    "\n",
    "def images_to_matrix(folder_path, convert_gray=True, rand=True, ratio=RATIO):\n",
    "    files = os.listdir(folder_path)\n",
    "    files.sort(key=lambda f: int(re.search(f\"{IMG_NAME}_(\\d+).png\", f).group(1)))\n",
    "    if rand:\n",
    "        random.seed(SEED)\n",
    "        random.shuffle(files)\n",
    "\n",
    "    total_files = len(files)\n",
    "    number_of_files_to_load = int(total_files * ratio)\n",
    "    selected_files = files[:number_of_files_to_load]\n",
    "    selected_files.sort(key=lambda f: int(re.search(f\"{IMG_NAME}_(\\d+).png\", f).group(1)))\n",
    "\n",
    "    images = []\n",
    "    use_list = []\n",
    "\n",
    "    for file in selected_files:\n",
    "        index = int(re.sub(r\"\\D\", \"\", file))\n",
    "        use_list.append(index)\n",
    "        img = Image.open(os.path.join(folder_path, file))\n",
    "        if convert_gray:\n",
    "            img = img.convert(\"L\")\n",
    "        img_array = np.asarray(img).flatten()\n",
    "        img_array = img_array / 255\n",
    "        images.append(img_array)\n",
    "\n",
    "    return np.column_stack(images), use_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prox_l1(y: cp.ndarray, tau: float) -> cp.ndarray:\n",
    "    return cp.sign(y) * cp.maximum(cp.absolute(y) - tau, 0)\n",
    "\n",
    "\n",
    "def prox_l122(y: cp.ndarray, gamma: float) -> cp.ndarray:\n",
    "    Y = cp.asarray(vector2matrixCp(y, M, N))\n",
    "    l1_norms = cp.sum(cp.absolute(Y), axis=1)\n",
    "    factor = (2 * gamma) / (1 + 2 * gamma * N)\n",
    "    X = cp.zeros_like(Y)\n",
    "    X = cp.sign(Y) * cp.maximum(cp.absolute(Y) - factor * l1_norms[:, None], 0)\n",
    "    return matrix2vectorCp(X)\n",
    "\n",
    "\n",
    "def prox_tv(y: cp.ndarray, gamma: float) -> cp.ndarray:\n",
    "    Dx_norm = cp.linalg.norm(y.reshape(-1, 4, order=\"F\"), axis=1).astype(cp.float32)\n",
    "    Dx_norm = cp.tile(Dx_norm[:, None], (1, 4))\n",
    "\n",
    "    prox = cp.maximum(1 - gamma / Dx_norm, 0) * y.reshape(-1, 4, order=\"F\")\n",
    "    prox = prox.reshape(-1, order=\"F\")\n",
    "\n",
    "    return prox\n",
    "\n",
    "\n",
    "def prox_conj(prox: Callable[[cp.ndarray, float], cp.ndarray], x: cp.ndarray, gamma: float) -> cp.ndarray:\n",
    "    \"\"\"Conjugate proximal operator.\"\"\"\n",
    "    return x - gamma * prox(x / gamma, 1 / gamma)\n",
    "\n",
    "\n",
    "def primal_dual_splitting(\n",
    "    X: cp.ndarray,\n",
    "    g: cp.ndarray,\n",
    "    lambda1: float,\n",
    "    lambda2: float,\n",
    "    max_iter: int = ITER,\n",
    "    tol: float = 1e-2\n",
    ") -> tuple[np.ndarray, dict]:\n",
    "    \"\"\"\n",
    "    Solve the optimization problem:\n",
    "    min_h ||g-Xh||_2^2 + lambda1 P(h) + lambda2 ||Dh||_{1,2}\n",
    "    using the primal-dual splitting method.\n",
    "\n",
    "    Args:\n",
    "        X (cp.ndarray): Matrix X in the problem formulation.\n",
    "        g (cp.ndarray): Vector g in the problem formulation.\n",
    "        lambda1 (float): Regularization parameter for L1 norm of h.\n",
    "        lambda2 (float): Regularization parameter for L1 norm of Dh.\n",
    "\n",
    "    Returns:\n",
    "        tuple[np.ndarray, dict]: Solution h and a dictionary containing additional information.\n",
    "    \"\"\"\n",
    "    h = cp.zeros(M * N).astype(cp.float32)\n",
    "    h_old = cp.zeros(M * N).astype(cp.float32)\n",
    "    y = cp.zeros(4 * M * N).astype(cp.float32)\n",
    "    y_old = cp.zeros(4 * M * N).astype(cp.float32)\n",
    "\n",
    "    # Compute Lipschitz constant of grad_f\n",
    "    # tau = 1.0 / (np.linalg.norm(X, 2) ** 2)  # 1 / Compute Lipschitz constant of grad_f\n",
    "    # sigma = 1.0 / ((2 * M * N * 2) ** 2)  # 1 / l2 norm of Dij ^ 2\n",
    "    tau = 1 / (4096 * 3)\n",
    "    sigma = 1 / (16384 * 3)\n",
    "    print(f\"tau={tau}, sigma={sigma}\")\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    for k in range(max_iter):\n",
    "        h_old = h.copy()\n",
    "        y_old = y.copy()\n",
    "\n",
    "        h = prox_l122(h_old - tau * (mult_mass(X.T, (mult_mass(X, h_old, M) - g), M) - mult_DijklT(y_old)), tau * lambda1)\n",
    "\n",
    "        y = prox_conj(prox_tv, y_old + sigma * mult_Dijkl(2 * h - h_old), sigma / lambda2)\n",
    "\n",
    "        if k == max_iter - 1:\n",
    "            primal_residual = cp.linalg.norm(h - h_old)\n",
    "            dual_residual = cp.linalg.norm(y - y_old)\n",
    "            print(f\"iter={k}, primal_res={primal_residual:.4f}, dual_res={dual_residual:.4f}\")\n",
    "            break\n",
    "        else:\n",
    "            print(f\"iter={k}\")\n",
    "\n",
    "    end = time.perf_counter()\n",
    "    info = {\n",
    "        \"iterations\": k + 1,\n",
    "        \"primal_residual\": primal_residual,\n",
    "        \"dual_residual\": dual_residual,\n",
    "        \"time\": end - start,\n",
    "    }\n",
    "\n",
    "    return cp.asnumpy(h), info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images\n",
    "G, _ = images_to_matrix(f\"{DATA_PATH}/{IMG_NAME}{n}_cap_R_230516_128/\")\n",
    "F, _ = images_to_matrix(f\"{DATA_PATH}/{IMG_NAME}{n}_input/\")\n",
    "print(\"K=\", F.shape[1])\n",
    "white_img = Image.open(f\"{DATA_PATH}/{IMG_NAME}{n}_cap_R_230516_128/{IMG_NAME}_1.png\")\n",
    "white_img = white_img.convert(\"L\")\n",
    "white_img = np.asarray(white_img) / 255\n",
    "white = white_img.flatten()\n",
    "white = white[:, np.newaxis]\n",
    "H1 = np.tile(white, F.shape[1])\n",
    "F_hat = 2 * F - 1\n",
    "g = matrix2vectorNp(2 * G - H1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_hat_T_gpu = cp.asarray(F_hat.T).astype(cp.float32)\n",
    "g_gpu = cp.asarray(g).astype(cp.float32)\n",
    "h, info = primal_dual_splitting(F_hat_T_gpu, g_gpu, LAMBDA1, LAMBDA2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = vector2matrixNp(h, M, N)\n",
    "np.save(f\"{DIRECTORY}/systemMatrix/H_matrix_{SETTING}.npy\", H)\n",
    "\n",
    "sample_image = Image.open(f\"{DATA_PATH}/sample_image64/Cameraman64.png\").convert('L')\n",
    "sample_image = np.asarray(sample_image).flatten() / 255\n",
    "\n",
    "Hf = H @ sample_image\n",
    "Hf_img = Hf.reshape(m, m)\n",
    "Hf_img = np.clip(Hf_img, 0, 1)\n",
    "Hf_pil = Image.fromarray((Hf_img * 255).astype(np.uint8), mode='L')\n",
    "\n",
    "FILENAME = f\"{SETTING}.png\"\n",
    "fig, ax = plt.subplots(figsize=Hf_img.shape[::-1], dpi=1, tight_layout=True)\n",
    "ax.imshow(Hf_pil, cmap='gray')\n",
    "ax.axis('off')\n",
    "fig.savefig(f\"{DIRECTORY}/{FILENAME}\", dpi=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_true = np.load(f\"{DATA_PATH}/systemMatrix/H_matrix_true.npy\")\n",
    "rem = np.linalg.norm(H_true - H, \"fro\")\n",
    "print(rem)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "from typing import Callable\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "import cupyx.scipy.sparse as csp\n",
    "import matplotlib.pyplot as plt\n",
    "import dask.array as da\n",
    "from dask_cuda import LocalCUDACluster\n",
    "from dask.distributed import Client\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import package.myUtil as myUtil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 256\n",
    "LAMBDA = 100\n",
    "RATIO = 0.05\n",
    "DO_THIN_OUT = False\n",
    "SAVE_AS_SPARSE = True\n",
    "DATA_PATH = \"../data\"\n",
    "# DATA_PATH = \"../../OneDrive - m.titech.ac.jp/Lab/data\"\n",
    "IMG_NAME = \"hadamard\"\n",
    "CAP_DATE = \"241205\"\n",
    "EXP_DATE = \"241206\"\n",
    "DIRECTORY = f\"{DATA_PATH}/{EXP_DATE}\"\n",
    "SETTING = f\"p-{int(100*RATIO)}_lmd-{LAMBDA}\"\n",
    "if DO_THIN_OUT:\n",
    "    SETTING = SETTING + \"to\"\n",
    "\n",
    "if not os.path.exists(DIRECTORY):\n",
    "    os.makedirs(DIRECTORY)\n",
    "if not os.path.exists(DIRECTORY + \"/systemMatrix\"):\n",
    "    os.makedirs(DIRECTORY + \"/systemMatrix\")\n",
    "use_list = myUtil.get_use_list(n*n, RATIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = myUtil.images2matrix(f\"{DATA_PATH}/{IMG_NAME}{n}_cap_{CAP_DATE}/\", use_list, thin_out=DO_THIN_OUT)\n",
    "F = myUtil.images2matrix(f\"{DATA_PATH}/{IMG_NAME}{n}_input/\", use_list).astype(cp.int8)\n",
    "M, K = G.shape\n",
    "N, K = F.shape\n",
    "print(\"G shape:\", G.shape, \"F shape:\", F.shape, \"M=\", M, \"N=\", N, \"K=\", K)\n",
    "print(\"G max:\", G.max(), \"G min:\", G.min(), \"F max:\", F.max(), \"F min:\", F.min())\n",
    "\n",
    "black = myUtil.calculate_bias(M, DATA_PATH, CAP_DATE)\n",
    "B = cp.tile(black[:, None], K)\n",
    "\n",
    "G = G - B\n",
    "\n",
    "white_img = Image.open(f\"{DATA_PATH}/capture_{CAP_DATE}/White.png\").convert(\"L\")\n",
    "white = (cp.asarray(white_img) / 255).astype(cp.float32)\n",
    "if DO_THIN_OUT:\n",
    "    white = white[::2, ::2].ravel() - black\n",
    "else:\n",
    "    white = white.ravel() - black\n",
    "H1 = cp.tile(white[:, None], K)\n",
    "\n",
    "F_hat = 2 * F - 1\n",
    "G_hat = 2 * G - H1\n",
    "del F, G, H1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distributed_matmul(A: np.ndarray, B: np.ndarray, M_block: int, K_block: int, gpu_ids=[0, 1, 2]):\n",
    "    \"\"\"\n",
    "    A, B: NumPy配列 (AはM×N, BはN×K)\n",
    "    M_block, K_block: ブロックサイズ\n",
    "    gpu_ids: 使用するGPU IDリスト\n",
    "\n",
    "    戻り値:\n",
    "        C: A@Bの結果を表すDask Array（cupyをバックエンドにしたブロック計算結果）\n",
    "    \"\"\"\n",
    "    # 行列サイズ取得\n",
    "    M, N = A.shape\n",
    "    N2, K = B.shape\n",
    "    if N != N2:\n",
    "        raise ValueError(\"行列サイズが不一致です。Aは(M×N), Bは(N×K)である必要があります。\")\n",
    "\n",
    "    # Dask + CUDA Cluster 設定\n",
    "    # 既にClusterやClientが存在する場合は、外部から渡せるよう拡張可能\n",
    "    cluster = LocalCUDACluster(n_workers=len(gpu_ids), threads_per_worker=1, CUDA_VISIBLE_DEVICES=gpu_ids)\n",
    "    client = Client(cluster)\n",
    "\n",
    "    # 行列A, BをDask配列化、チャンク分割\n",
    "    # Aは行方向にM_blockごと、Bは列方向にK_blockごと分割\n",
    "    A_d = da.from_array(A, chunks=(M_block, N))\n",
    "    B_d = da.from_array(B, chunks=(N, K_block))\n",
    "\n",
    "    # ブロックをcupy配列に変換\n",
    "    A_c = A_d.map_blocks(cp.asarray, dtype=A_d.dtype)\n",
    "    B_c = B_d.map_blocks(cp.asarray, dtype=B_d.dtype)\n",
    "\n",
    "    # 行列積計算 (ブロックごとにGPUで計算)\n",
    "    C_c = da.dot(A_c, B_c)\n",
    "\n",
    "    # 計算を開始\n",
    "    # C_cはDask配列。persistで計算をスケジューラに渡す(遅延評価解消)\n",
    "    C_c = C_c.persist()\n",
    "    client.wait(C_c)\n",
    "\n",
    "    # cluster, clientをこの関数内で作成した場合、必要に応じて後でclose可能\n",
    "    # ここでは返り値としてC_c（Dask Array）を返す\n",
    "    return C_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prox_l122(Y: cp.ndarray, gamma: float) -> csp.csr_matrix:\n",
    "    factor = (2 * gamma) / (1 + 2 * gamma * N)\n",
    "    l1_norms = cp.sum(cp.absolute(Y), axis=1)\n",
    "    X = cp.sign(Y) * cp.maximum(cp.absolute(Y) - factor * l1_norms[:, None], 0)\n",
    "    return csp.csr_matrix(X)\n",
    "    # return X\n",
    "\n",
    "\n",
    "def fista(\n",
    "    Ft: cp.ndarray,\n",
    "    Gt: cp.ndarray,\n",
    "    lmd: float,\n",
    "    prox: Callable[[cp.ndarray, float], cp.ndarray],\n",
    "    max_iter: int = 500,\n",
    "    tol: float = 1e-3,\n",
    ") -> cp.ndarray:\n",
    "    \"\"\"\n",
    "    Solve the optimization problem using FISTA:\n",
    "    min_h ||g - Xh||_2^2 + lambda * ||h||_1,2^2\n",
    "\n",
    "    Parameters:\n",
    "    - Ft: numpy array, the matrix Ft\n",
    "    - g: numpy array, the vector g\n",
    "    - lmd: float, the regularization parameter\n",
    "\n",
    "    Returns:\n",
    "    - h: numpy array, the solution vector h\n",
    "    \"\"\"\n",
    "    N = Ft.shape[1]\n",
    "    M = Gt.shape[1]\n",
    "    t = 1\n",
    "    # Ht = cp.zeros((N, M), dtype=cp.float32)\n",
    "    # Ht_old = cp.zeros_like(Ht)\n",
    "    Ht = csp.csr_matrix((N, M), dtype=cp.float32)\n",
    "    Ht_old = csp.csr_matrix((N, M), dtype=cp.float32)\n",
    "    Yt = cp.zeros((N, M), dtype=cp.float32)\n",
    "    # fft = Ft.T @ Ft\n",
    "    fft=distributed_matmul(Ft.T, Ft, 4096, 4096)\n",
    "    # fgt = Ft.T @ Gt\n",
    "    fgt = distributed_matmul(Ft.T, Gt, 4096, 4096)\n",
    "\n",
    "    # Lipschitz constant\n",
    "    # L = np.linalg.norm(Ft.T @ Ft, ord=2) * 3\n",
    "    gamma = 1 / (N * 3)\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        t_old = t\n",
    "        Ht_old = Ht.copy()\n",
    "\n",
    "        A_dense = Yt - gamma * fft @ Ht - fgt\n",
    "        Ht = prox(A_dense, gamma * lmd)\n",
    "        # Ht = prox(Yt - gamma * fft @ Ht - Ft.T @ Gt, gamma * lmd)\n",
    "        t = (1 + np.sqrt(1 + 4 * t_old**2)) / 2\n",
    "        Yt = Ht + ((t_old - 1) / t) * (Ht - Ht_old)\n",
    "\n",
    "        # error = cp.linalg.norm(Ht - Ht_old) / cp.linalg.norm(Ht)\n",
    "        error = csp.linalg.norm(Ht - Ht_old) / csp.linalg.norm(Ht)\n",
    "        print(f\"iter: {i}, error: {error}\")\n",
    "        # rem = cp.linalg.norm(Ht - H_true.T)\n",
    "        # print(f\"iter: {i}, error: {error}, rem: {rem}\")\n",
    "        if error < tol:\n",
    "            break\n",
    "\n",
    "    return Ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ht = fista(F_hat.T, G_hat.T, LAMBDA, prox_l122)\n",
    "H = Ht.T\n",
    "del Ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE_AS_SPARSE:\n",
    "    print(f\"shape: {H.shape}, nnz: {H.nnz}({H.nnz / H.shape[0] / H.shape[1] * 100:.2f}%)\")\n",
    "    H_np = {\n",
    "        \"data\": cp.asnumpy(H.data),\n",
    "        \"indices\": cp.asnumpy(H.indices),\n",
    "        \"indptr\": cp.asnumpy(H.indptr),\n",
    "        \"shape\": H.shape\n",
    "    }\n",
    "    np.savez(f\"{DIRECTORY}/systemMatrix/H_matrix_{SETTING}.npz\", **H_np)\n",
    "    print(f\"Saved {DIRECTORY}/systemMatrix/H_matrix_{SETTING}.npz\")\n",
    "    # myUtil.plot_sparse_matrix_cupy(H, row_range=(5500, 6000), col_range=(4500, 5000), markersize=1)\n",
    "else:\n",
    "    cp.save(f\"{DIRECTORY}/systemMatrix/H_matrix_{SETTING}.npy\", H)\n",
    "    print(f\"Saved {DIRECTORY}/systemMatrix/H_matrix_{SETTING}.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_NAME = \"Cameraman\"\n",
    "sample_image = Image.open(f\"{DATA_PATH}/sample_image{n}/{SAMPLE_NAME}.png\").convert(\"L\")\n",
    "sample_image = cp.asarray(sample_image).flatten() / 255\n",
    "\n",
    "m = int(math.sqrt(M))\n",
    "FILENAME = f\"{SAMPLE_NAME}_{SETTING}.png\"\n",
    "Hf = H @ sample_image + black\n",
    "Hf = cp.asnumpy(Hf.reshape(m, m))\n",
    "print(\"Hf shape:\", Hf.shape)\n",
    "\n",
    "Hf_pil = Image.fromarray((Hf * 255).astype(np.uint8), mode=\"L\")\n",
    "Hf_pil.save(f\"{DIRECTORY}/{FILENAME}\", format='PNG')\n",
    "print(f\"Saved {DIRECTORY}/{FILENAME}\")\n",
    "display(Hf_pil)\n",
    "\n",
    "plt.imshow(Hf, cmap='gray', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.title('Grayscale Heatmap')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

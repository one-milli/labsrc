{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最適化問題\n",
    "\n",
    "$$ \\min_h \\frac{1}{2}\\|\\bm{g}-(I\\otimes F^\\top) \\bm{h}\\|_2^2+\\lambda_1\\|\\bm{h}\\|_{1,2}^2 + \\lambda_2\\|D\\bm{h}\\|_{1,2}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from typing import Callable\n",
    "import cupy as cp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import package.myUtil as myUtil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 64\n",
    "m = 128\n",
    "N = n**2\n",
    "M = m**2\n",
    "LAMBDA1 = 1\n",
    "LAMBDA2 = 1\n",
    "TAU = 1e-4\n",
    "SIGMA = 1e-4\n",
    "SEED = 5\n",
    "RATIO = 0.05\n",
    "ITER = 1000\n",
    "DATA_PATH = \"../../OneDrive - m.titech.ac.jp/Lab/data\"\n",
    "# DATA_PATH = \"../data\"\n",
    "IMG_NAME = \"hadamard\"\n",
    "DIRECTORY = DATA_PATH + \"/241005\"\n",
    "SETTING = f\"{IMG_NAME}_pr-du_p-{int(100*RATIO)}_lmd1-{LAMBDA1}_lmd2-{LAMBDA2}_t{int(math.log10(TAU))}_s{int(math.log10(SIGMA))}\"\n",
    "\n",
    "if not os.path.exists(DIRECTORY):\n",
    "    os.makedirs(DIRECTORY)\n",
    "if not os.path.exists(DIRECTORY + \"/systemMatrix\"):\n",
    "    os.makedirs(DIRECTORY + \"/systemMatrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_memory_usage(message):\n",
    "    mempool = cp.get_default_memory_pool()\n",
    "    used_bytes = mempool.used_bytes()\n",
    "    total_bytes = mempool.total_bytes()\n",
    "    print(f\"{message}: Used memory: {used_bytes / 1024**3:.2f} GB, Total memory: {total_bytes / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mult_D(h):\n",
    "    tensor = h.reshape((n, n, m, m), order='F')\n",
    "\n",
    "    di = cp.zeros_like(tensor)\n",
    "    dj = cp.zeros_like(tensor)\n",
    "    dk = cp.zeros_like(tensor)\n",
    "    dl = cp.zeros_like(tensor)\n",
    "\n",
    "    di[1:, :, :, :] = tensor[1:, :, :, :] - tensor[:-1, :, :, :]\n",
    "    dj[:, 1:, :, :] = tensor[:, 1:, :, :] - tensor[:, :-1, :, :]\n",
    "    dk[:, :, 1:, :] = tensor[:, :, 1:, :] - tensor[:, :, :-1, :]\n",
    "    dl[:, :, :, 1:] = tensor[:, :, :, 1:] - tensor[:, :, :, :-1]\n",
    "\n",
    "    di_flat = di.ravel(order='F')\n",
    "    dj_flat = dj.ravel(order='F')\n",
    "    dk_flat = dk.ravel(order='F')\n",
    "    dl_flat = dl.ravel(order='F')\n",
    "\n",
    "    Dh = cp.concatenate([di_flat, dj_flat, dk_flat, dl_flat])\n",
    "\n",
    "    return Dh\n",
    "\n",
    "\n",
    "def mult_Dt(y):\n",
    "    length = n * n * m * m\n",
    "\n",
    "    di_flat = y[0:length]\n",
    "    dj_flat = y[length:2*length]\n",
    "    dk_flat = y[2*length:3*length]\n",
    "    dl_flat = y[3*length:4*length]\n",
    "\n",
    "    di = di_flat.reshape((n, n, m, m), order='F')\n",
    "    dj = dj_flat.reshape((n, n, m, m), order='F')\n",
    "    dk = dk_flat.reshape((n, n, m, m), order='F')\n",
    "    dl = dl_flat.reshape((n, n, m, m), order='F')\n",
    "\n",
    "    h_tensor = cp.zeros((n, n, m, m))\n",
    "\n",
    "    h_tensor[:-1, :, :, :] -= di[1:, :, :, :]\n",
    "    h_tensor[1:, :, :, :] += di[1:, :, :, :]\n",
    "\n",
    "    h_tensor[:, :-1, :, :] -= dj[:, 1:, :, :]\n",
    "    h_tensor[:, 1:, :, :] += dj[:, 1:, :, :]\n",
    "\n",
    "    h_tensor[:, :, :-1, :] -= dk[:, :, 1:, :]\n",
    "    h_tensor[:, :, 1:, :] += dk[:, :, 1:, :]\n",
    "\n",
    "    h_tensor[:, :, :, :-1] -= dl[:, :, :, 1:]\n",
    "    h_tensor[:, :, :, 1:] += dl[:, :, :, 1:]\n",
    "\n",
    "    h = h_tensor.ravel(order='F')\n",
    "\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_1st_term(Gt, Ft, Ht):\n",
    "    print(\"calculate_1st_term start\")\n",
    "    return cp.linalg.norm(Gt - Ft @ Ht) ** 2\n",
    "\n",
    "\n",
    "def calculate_2nd_term(H):\n",
    "    print(\"calculate_2nd_term start\")\n",
    "    column_sums = cp.sum(cp.abs(H), axis=1)\n",
    "    result = cp.sum(column_sums**2)\n",
    "    return result\n",
    "\n",
    "\n",
    "def calculate_3rd_term(h):\n",
    "    print(\"calculate_3rd_term start\")\n",
    "    Du = mult_D(h)\n",
    "    Du = Du.reshape(-1, 4, order=\"F\")\n",
    "    tv = cp.sum(cp.linalg.norm(Du, axis=1))\n",
    "    return tv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prox_l122(Ht: cp.ndarray, gamma: float) -> cp.ndarray:\n",
    "    l1_norms = cp.sum(cp.absolute(Ht), axis=1)\n",
    "    factor = (2 * gamma) / (1 + 2 * gamma * N)\n",
    "    X = cp.zeros_like(Ht)\n",
    "    X = cp.sign(Ht) * cp.maximum(cp.absolute(Ht) - factor * l1_norms[:, None], 0)\n",
    "    return X\n",
    "\n",
    "\n",
    "def prox_tv(y: cp.ndarray, gamma: float) -> cp.ndarray:\n",
    "    l2 = cp.linalg.norm(y.reshape(-1, 4, order=\"F\"), axis=1, keepdims=True)\n",
    "    l2 = cp.maximum(1 - gamma / (l2 + 1e-16), 0)\n",
    "    return (l2 * y.reshape(-1, 4, order=\"F\")).ravel(order=\"F\")\n",
    "\n",
    "\n",
    "def prox_conj(y: cp.ndarray, prox: Callable[[cp.ndarray, float], cp.ndarray], gamma: float) -> cp.ndarray:\n",
    "    \"\"\"Conjugate proximal operator.\"\"\"\n",
    "    return y - gamma * prox(y / gamma, 1 / gamma)\n",
    "\n",
    "\n",
    "def primal_dual_splitting(\n",
    "    Ft: cp.ndarray, Gt: cp.ndarray, lambda1: float, lambda2: float, max_iter: int = ITER\n",
    ") -> tuple[cp.ndarray, dict]:\n",
    "\n",
    "    N = Ft.shape[1]\n",
    "    M = Gt.shape[1]\n",
    "    print_memory_usage(\"Before initializing variables\")\n",
    "    Ht = cp.zeros((N, M), dtype=cp.float32)\n",
    "    Ht_old = cp.zeros_like(Ht)\n",
    "    y = cp.zeros(4 * N * M, dtype=cp.float32)\n",
    "    y_old = cp.zeros_like(y)\n",
    "    print_memory_usage(\"After initializing variables\")\n",
    "\n",
    "    tau = TAU\n",
    "    sigma = SIGMA\n",
    "    print(f\"tau={tau}, sigma={sigma}\")\n",
    "\n",
    "    for k in range(max_iter):\n",
    "        Ht_old[:] = Ht[:]\n",
    "        y_old[:] = y[:]\n",
    "\n",
    "        Ht[:] = prox_l122(\n",
    "            Ht_old - tau * (Ft.T @ (Ft @ Ht - Gt) + (mult_Dt(y_old)).reshape(N, M, order=\"F\")),\n",
    "            lambda1 * tau,\n",
    "        )\n",
    "\n",
    "        y[:] = prox_conj(y_old + sigma * mult_D((2 * Ht - Ht_old).ravel(order=\"F\")), prox_tv, lambda2 / sigma)\n",
    "\n",
    "        if k % 20 == 19:\n",
    "            primal_residual = cp.linalg.norm(Ht - Ht_old) / cp.linalg.norm(Ht)\n",
    "            dual_residual = cp.linalg.norm(y - y_old) / cp.linalg.norm(y)\n",
    "            print(f\"iter={k}, primal_res={primal_residual:.8e}, dual_res={dual_residual:.8e}\")\n",
    "            print(\"1st\", calculate_1st_term(Gt, Ft, Ht))\n",
    "            print(\"2nd\", calculate_2nd_term(Ht))\n",
    "            print(\"3rd\", calculate_3rd_term(Ht))\n",
    "            if cp.isnan(primal_residual) or cp.isnan(dual_residual):\n",
    "                print(\"NaN detected in residuals, stopping optimization.\")\n",
    "                break\n",
    "            if primal_residual < 1e-3 and dual_residual < 1e-3:\n",
    "                print(\"Convergence criteria met.\")\n",
    "                break\n",
    "        else:\n",
    "            print(f\"iter={k}\")\n",
    "\n",
    "    primal_residual = cp.linalg.norm(Ht - Ht_old)\n",
    "    dual_residual = cp.linalg.norm(y - y_old)\n",
    "    print(f\"Final iteration {k+1}, primal_res={primal_residual:.8e}, dual_res={dual_residual:.8e}\")\n",
    "    print_memory_usage(\"After optimization\")\n",
    "\n",
    "    info = {\n",
    "        \"iterations\": k + 1,\n",
    "        \"primal_residual\": primal_residual,\n",
    "        \"dual_residual\": dual_residual,\n",
    "    }\n",
    "\n",
    "    return Ht, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images\n",
    "INFO = \"cap_R_230516_128\"\n",
    "# INFO = \"cap_240814\"\n",
    "G, _ = myUtil.images_to_matrix(f\"{DATA_PATH}/{IMG_NAME}{n}_{INFO}/\", ratio=RATIO, resize=True, ressize=m)\n",
    "F, _ = myUtil.images_to_matrix(f\"{DATA_PATH}/{IMG_NAME}{n}_input/\", ratio=RATIO)\n",
    "K = F.shape[1]\n",
    "print(\"K=\", K)\n",
    "white_img = Image.open(f\"{DATA_PATH}/{IMG_NAME}{n}_{INFO}/{IMG_NAME}_1.png\").convert(\"L\")\n",
    "white_img = white_img.resize((m, m))\n",
    "white = np.asarray(white_img).ravel() / 255\n",
    "white = white[:, np.newaxis]\n",
    "H1 = np.tile(white, F.shape[1])\n",
    "F_hat = 2 * F - 1\n",
    "G_hat = 2 * G - H1\n",
    "# G_vec = G_hat.ravel(order=\"F\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_hat_T_gpu = cp.asarray(F_hat.T).astype(cp.int8)\n",
    "G_hat_T_gpu = cp.asarray(G_hat.T).astype(cp.float32)\n",
    "\n",
    "print(f\"F device: {F_hat_T_gpu.device}\")\n",
    "print(f\"g device: {G_hat_T_gpu.device}\")\n",
    "del F, G, H1, F_hat, G_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, info = primal_dual_splitting(F_hat_T_gpu, G_hat_T_gpu, LAMBDA1, LAMBDA2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ht = h.reshape(N, M, order=\"F\")\n",
    "# np.save(f\"{DIRECTORY}/systemMatrix/H_matrix_{SETTING}.npy\", H)\n",
    "# print(f\"Saved {DIRECTORY}/systemMatrix/H_matrix_{SETTING}.npy\")\n",
    "\n",
    "SAMPLE_NAME = \"Cameraman\"\n",
    "sample_image = Image.open(f\"{DATA_PATH}/sample_image{n}/{SAMPLE_NAME}.png\").convert('L')\n",
    "sample_image = cp.asarray(sample_image).ravel() / 255\n",
    "\n",
    "Hf = Ht.T @ sample_image\n",
    "Hf_img = cp.asnumpy(Hf.reshape(m, m))\n",
    "Hf_img = np.clip(Hf_img, 0, 1)\n",
    "Hf_pil = Image.fromarray((Hf_img * 255).astype(np.uint8), mode='L')\n",
    "\n",
    "FILENAME = f\"{SAMPLE_NAME}_{SETTING}.png\"\n",
    "fig, ax = plt.subplots(figsize=Hf_img.shape[::-1], dpi=1, tight_layout=True)\n",
    "ax.imshow(Hf_pil, cmap='gray')\n",
    "ax.axis('off')\n",
    "fig.savefig(f\"{DIRECTORY}/{FILENAME}\", dpi=1)\n",
    "# plt.show()\n",
    "print(f\"Saved {DIRECTORY}/{FILENAME}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
